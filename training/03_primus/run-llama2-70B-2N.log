========== Slurm cluster info ==========
SLURM_NODELIST: gpu-11 gpu-12
SLURM_NNODES: 2
SLURM_GPUS_ON_NODE: 

========== Cluster info ==========
MASTER_ADDR: gpu-11
MASTER_PORT: 12345
NNODES: 2
GPUS_PER_NODE: 8

Node-0: Cleaning up existing containers...
Node-1: Cleaning up existing containers...
Node-0: No containers to remove.
Node-1: No containers to remove.
[NODE-0(gpu-11)]: begin, time=2025.11.14 07:53:06
[NODE-0(gpu-11)] [INFO] ==========Training cluster info==========
[NODE-0(gpu-11)] [INFO] MASTER_ADDR: gpu-11
[NODE-0(gpu-11)] [INFO] MASTER_PORT: 12345
[NODE-0(gpu-11)] [INFO] NNODES: 2
[NODE-0(gpu-11)] [INFO] NODE_RANK: 0
[NODE-0(gpu-11)] [INFO] GPUS_PER_NODE: 8

[NODE-1(gpu-12)]: begin, time=2025.11.14 07:53:07

[notice] A new release of pip is available: 25.2 -> 25.3
[notice] To update, run: pip install --upgrade pip

[notice] A new release of pip is available: 25.2 -> 25.3
[notice] To update, run: pip install --upgrade pip
[NODE-0(gpu-11)] [INFO] ==========Training info==========
[NODE-0(gpu-11)] [INFO] EXP: examples/megatron/configs/llama2_70B-pretrain.yaml
[NODE-0(gpu-11)] [INFO] TRAIN_LOG: output/log_torchrun_pretrain_llama2_70B-pretrain.txt
[NODE-0(gpu-11)] [INFO] PRIMUS_PATH: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus
[NODE-0(gpu-11)] [INFO] DATA_PATH: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/data
[NODE-0(gpu-11)] [INFO] HF_HOME: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/data/huggingface

[NODE-0(gpu-11)] [INFO] ==========NCCL and Network Settings==========
[NODE-0(gpu-11)] [INFO] NCCL_DEBUG: 
[NODE-0(gpu-11)] [INFO] NCCL_CHECKS_DISABLE: 1
[NODE-0(gpu-11)] [INFO] NCCL_IB_GID_INDEX: 3
[NODE-0(gpu-11)] [INFO] NCCL_CROSS_NIC: 0
[NODE-0(gpu-11)] [INFO] NCCL_IB_HCA: bnxt_re0:1,bnxt_re1:1,bnxt_re2:1,bnxt_re3:1,bnxt_re4:1,bnxt_re5:1,bnxt_re7:1,bnxt_re8:1
[NODE-0(gpu-11)] [INFO] NCCL_SOCKET_IFNAME: enp49s0f1np1
[NODE-0(gpu-11)] [INFO] GLOO_SOCKET_IFNAME: enp49s0f1np1

[NODE-0(gpu-11)] [INFO] ==========AMD-specific GPU optimizations==========
[NODE-0(gpu-11)] [INFO] HSA_ENABLE_SDMA: 1
[NODE-0(gpu-11)] [INFO] HSA_NO_SCRATCH_RECLAIM: 1
[NODE-0(gpu-11)] [INFO] RCCL_MSCCL_ENABLE: 0
[NODE-0(gpu-11)] [INFO] RCCL_MSCCLPP_ENABLE: 0
[NODE-0(gpu-11)] [INFO] RCCL_MSCCLPP_FORCE_ENABLE: 0
[NODE-0(gpu-11)] [INFO] RCCL_MSCCLPP_THRESHOLD: 1073741824
[NODE-0(gpu-11)] [INFO] MSCCLPP_DISABLE_CHANNEL_CACHE: FALSE
[NODE-0(gpu-11)] [INFO] TORCH_NCCL_USE_TENSOR_REGISTER_ALLOCATOR_HOOK: 0

[NODE-0(gpu-11)] [INFO] ==========Performance tuning==========
[NODE-0(gpu-11)] [INFO] GPU_MAX_HW_QUEUES: 2
[NODE-0(gpu-11)] [INFO] CUDA_DEVICE_MAX_CONNECTIONS: 1
[NODE-0(gpu-11)] [INFO] TORCH_NCCL_HIGH_PRIORITY: 1
[NODE-0(gpu-11)] [INFO] CUDA_DEVICE_MAX_CONNECTIONS: 1
[NODE-0(gpu-11)] [INFO] TORCH_NCCL_HIGH_PRIORITY: 1
[NODE-0(gpu-11)] [INFO] NCCL_PXN_DISABLE: 1
[NODE-0(gpu-11)] [INFO] NCCL_P2P_NET_CHUNKSIZE: 524288
[NODE-0(gpu-11)] [INFO] NVTE_CK_USES_BWD_V3: 1
[NODE-0(gpu-11)] [INFO] NVTE_USE_CAST_TRANSPOSE_TRITON: 1
[NODE-0(gpu-11)] [INFO] NVTE_USE_OPTIMIZED_HIPIFIED_CAST_TRANSPOSE: 0

[NODE-0(gpu-11)] [INFO] Rebuilding bnxt from /shared/amdgpu/home/hisaki_ohara_7kq/libbnxt_re-231.0.162.0.tar.gz ...
[NODE-1(gpu-12)] [INFO] NCCL_IB_HCA: bnxt_re0:1,bnxt_re1:1,bnxt_re2:1,bnxt_re3:1,bnxt_re4:1,bnxt_re5:1,bnxt_re7:1,bnxt_re8:1
[NODE-1(gpu-12)] [INFO] NCCL_SOCKET_IFNAME: enp49s0f1np1
[NODE-1(gpu-12)] [INFO] GLOO_SOCKET_IFNAME: enp49s0f1np1

[NODE-1(gpu-12)] [INFO] Rebuilding bnxt from /shared/amdgpu/home/hisaki_ohara_7kq/libbnxt_re-231.0.162.0.tar.gz ...

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.


WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

Reading package lists...
Reading package lists...
Building dependency tree...
Reading state information...
Building dependency tree...
Reading state information...
libelf-dev is already the newest version (0.186-1ubuntu0.1).
libelf-dev set to manually installed.
The following packages were automatically installed and are no longer required:
  adwaita-icon-theme amd-smi-lib at-spi2-core composablekernel-dev
  dbus-user-session dconf-gsettings-backend dconf-service fontconfig gdal-data
  gdb gsettings-desktop-schemas gstreamer1.0-plugins-base
  gtk-update-icon-cache half hicolor-icon-theme hip-dev hip-doc hip-samples
  hipcc hipcub-dev hipfft hipfft-dev hipfort-dev hipify-clang hiprand
  hiprand-dev hipsparse hipsparse-dev hipsparselt hipsparselt-dev hiptensor
  hiptensor-dev hsa-amd-aqlprofile hsa-rocr-dev humanity-icon-theme
  i965-va-driver ibverbs-providers icu-devtools intel-media-va-driver libaacs0
  libaec0 libaom3 libarchive13 libarmadillo10 libarpack2 libatk-bridge2.0-0
  libatk1.0-0 libatk1.0-data libatspi2.0-0 libavahi-client3
  libavahi-common-data libavahi-common3 libavcodec-dev libavcodec58
  libavformat-dev libavformat58 libavutil-dev libavutil56 libbabeltrace1
  libbdplus0 libblosc1 libbluray2 libboost-regex1.74.0 libc6-dbg
  libcairo-gobject2 libcairo2 libcdparanoia0 libcfitsio9 libcharls2
  libchromaprint1 libcodec2-1.0 libcolord2 libcups2 libdatrie1 libdav1d5
  libdc1394-25 libdc1394-dev libdconf1 libde265-0 libdebuginfod-common
  libdebuginfod1 libdeflate-dev libdouble-conversion3 libdrm-amdgpu-dev
  libdrm-amdgpu-radeon1 libdrm-dev libdrm-intel1 libdrm-nouveau2
  libdrm-radeon1 libepoxy0 libevent-core-2.1-7 libevent-pthreads-2.1-7
  libexif-dev libexif-doc libexif12 libfabric1 libfile-copy-recursive-perl
  libfile-listing-perl libfile-which-perl libfreexl1 libfribidi0 libfyba0
  libgdal30 libgdcm-dev libgdcm3.0 libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin
  libgdk-pixbuf2.0-common libgeos-c1v5 libgeos3.10.2 libgeotiff5 libgif7
  libgl-dev libgl1 libgl1-amber-dri libgl1-mesa-dri libgl2ps1.4 libglapi-mesa
  libglew2.2 libglvnd0 libglx-dev libglx-mesa0 libglx0 libgme0 libgphoto2-6
  libgphoto2-dev libgphoto2-l10n libgphoto2-port12 libgraphite2-3 libgsm1
  libgstreamer-plugins-base1.0-0 libgtk-3-0 libgtk-3-bin libgtk-3-common
  libharfbuzz0b libhdf4-0-alt libhdf5-103-1 libhdf5-hl-100 libheif1
  libhttp-date-perl libhwloc-plugins libhwloc15 libibverbs1 libicu-dev
  libigdgmm12 libilmbase-dev libilmbase25 libipt2 libjbig-dev libjpeg-dev
  libjpeg-turbo8-dev libjpeg8-dev libjsoncpp25 libkmlbase1 libkmldom1
  libkmlengine1 liblcms2-2 liblept5 libllvm15 liblzma-dev libmfx1 libminizip1
  libmp3lame0 libmpg123-0 libmysqlclient21 libnetcdf19 libnl-route-3-200
  libnorm1 libnspr4 libnss3 libnuma-dev libodbc2 libodbcinst2 libogdi4.1
  libogg0 libopencv-calib3d-dev libopencv-calib3d4.5d libopencv-contrib-dev
  libopencv-contrib4.5d libopencv-core-dev libopencv-core4.5d libopencv-dev
  libopencv-dnn-dev libopencv-dnn4.5d libopencv-features2d-dev
  libopencv-features2d4.5d libopencv-flann-dev libopencv-flann4.5d
  libopencv-highgui-dev libopencv-highgui4.5d libopencv-imgcodecs-dev
  libopencv-imgcodecs4.5d libopencv-imgproc-dev libopencv-imgproc4.5d
  libopencv-ml-dev libopencv-ml4.5d libopencv-objdetect-dev
  libopencv-objdetect4.5d libopencv-photo-dev libopencv-photo4.5d
  libopencv-shape-dev libopencv-shape4.5d libopencv-stitching-dev
  libopencv-stitching4.5d libopencv-superres-dev libopencv-superres4.5d
  libopencv-video-dev libopencv-video4.5d libopencv-videoio-dev
  libopencv-videoio4.5d libopencv-videostab-dev libopencv-videostab4.5d
  libopencv-viz-dev libopencv-viz4.5d libopencv4.5-java libopencv4.5d-jni
  libopenexr-dev libopenexr25 libopengl0 libopenjp2-7 libopenmpi3 libopenmpt0
  libopus0 liborc-0.4-0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0
  libpciaccess-dev libpciaccess0 libpgm-5.3-0 libpixman-1-0 libpmix2
  libpng-dev libpng-tools libpoppler118 libpq5 libproj22 libprotobuf23
  libpsm-infinipath1 libpsm2-2 libpthread-stubs0-dev libqhull-r8.0
  librabbitmq4 libraw1394-11 libraw1394-dev libraw1394-tools librdmacm1
  librsvg2-2 librsvg2-common librttopo1 libsensors-config libsensors5
  libshine3 libsnappy1v5 libsocket++1 libsodium23 libsource-highlight-common
  libsource-highlight4v5 libsoxr0 libspatialite7 libspeex1 libsrt1.4-gnutls
  libssh-gcrypt-4 libstdc++-12-dev libsuperlu5 libswresample-dev
  libswresample3 libswscale-dev libswscale5 libsz2 libtbb-dev libtbb12 libtbb2
  libtbbmalloc2 libtcl8.6 libtesseract4 libthai-data libthai0 libtheora0
  libtiff-dev libtiffxx5 libtimedate-perl libtk8.6 libtwolame0 libucx0
  libudfread0 liburi-perl liburiparser1 libusb-1.0-0 libva-drm2 libva-x11-2
  libva2 libvdpau1 libvisual-0.4-0 libvorbis0a libvorbisenc2 libvorbisfile3
  libvpx7 libvtk9.1 libwayland-client0 libwayland-cursor0 libwayland-egl1
  libwebpmux3 libx11-dev libx11-xcb1 libx264-163 libx265-199 libxau-dev
  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0
  libxcb-render0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1-dev
  libxcomposite1 libxcursor1 libxdamage1 libxdmcp-dev libxerces-c3.2
  libxfixes3 libxft2 libxi6 libxinerama1 libxkbcommon0 libxml2-dev libxnvctrl0
  libxrandr2 libxrender1 libxshmfence1 libxss1 libxtst6 libxvidcore4
  libxxf86vm1 libzmq5 libzvbi-common libzvbi0 mesa-common-dev mesa-va-drivers
  mesa-vdpau-drivers mysql-common ocl-icd-libopencl1 ocl-icd-opencl-dev
  opencl-c-headers opencl-clhpp-headers opencv-data openmp-extras-dev
  openmp-extras-runtime pkg-config poppler-data proj-bin proj-data
  python3-argcomplete rccl rccl-dev rocfft rocfft-dev rocm-cmake rocm-dbgapi
  rocm-debug-agent rocm-developer-tools rocm-gdb rocm-hip-runtime
  rocm-hip-runtime-dev rocm-language-runtime rocm-opencl rocm-opencl-dev
  rocm-opencl-sdk rocm-openmp rocm-smi-lib rocprim-dev rocprofiler
  rocprofiler-compute rocprofiler-dev rocprofiler-plugins rocprofiler-sdk
  rocprofiler-sdk-rocpd rocprofiler-sdk-roctx rocprofiler-systems
  rocthrust-dev roctracer-dev rocwmma-dev rpp rpp-dev session-migration tzdata
  ubuntu-mono unixodbc-common va-driver-all valgrind vdpau-driver-all
  x11-common x11proto-dev xkb-data xorg-sgml-doctools xtrans-dev
Use 'apt autoremove' to remove them.
libelf-dev is already the newest version (0.186-1ubuntu0.1).
libelf-dev set to manually installed.
The following packages were automatically installed and are no longer required:
  adwaita-icon-theme amd-smi-lib at-spi2-core composablekernel-dev
  dbus-user-session dconf-gsettings-backend dconf-service fontconfig gdal-data
  gdb gsettings-desktop-schemas gstreamer1.0-plugins-base
  gtk-update-icon-cache half hicolor-icon-theme hip-dev hip-doc hip-samples
  hipcc hipcub-dev hipfft hipfft-dev hipfort-dev hipify-clang hiprand
  hiprand-dev hipsparse hipsparse-dev hipsparselt hipsparselt-dev hiptensor
  hiptensor-dev hsa-amd-aqlprofile hsa-rocr-dev humanity-icon-theme
  i965-va-driver ibverbs-providers icu-devtools intel-media-va-driver libaacs0
  libaec0 libaom3 libarchive13 libarmadillo10 libarpack2 libatk-bridge2.0-0
  libatk1.0-0 libatk1.0-data libatspi2.0-0 libavahi-client3
  libavahi-common-data libavahi-common3 libavcodec-dev libavcodec58
  libavformat-dev libavformat58 libavutil-dev libavutil56 libbabeltrace1
  libbdplus0 libblosc1 libbluray2 libboost-regex1.74.0 libc6-dbg
  libcairo-gobject2 libcairo2 libcdparanoia0 libcfitsio9 libcharls2
  libchromaprint1 libcodec2-1.0 libcolord2 libcups2 libdatrie1 libdav1d5
  libdc1394-25 libdc1394-dev libdconf1 libde265-0 libdebuginfod-common
  libdebuginfod1 libdeflate-dev libdouble-conversion3 libdrm-amdgpu-dev
  libdrm-amdgpu-radeon1 libdrm-dev libdrm-intel1 libdrm-nouveau2
  libdrm-radeon1 libepoxy0 libevent-core-2.1-7 libevent-pthreads-2.1-7
  libexif-dev libexif-doc libexif12 libfabric1 libfile-copy-recursive-perl
  libfile-listing-perl libfile-which-perl libfreexl1 libfribidi0 libfyba0
  libgdal30 libgdcm-dev libgdcm3.0 libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin
  libgdk-pixbuf2.0-common libgeos-c1v5 libgeos3.10.2 libgeotiff5 libgif7
  libgl-dev libgl1 libgl1-amber-dri libgl1-mesa-dri libgl2ps1.4 libglapi-mesa
  libglew2.2 libglvnd0 libglx-dev libglx-mesa0 libglx0 libgme0 libgphoto2-6
  libgphoto2-dev libgphoto2-l10n libgphoto2-port12 libgraphite2-3 libgsm1
  libgstreamer-plugins-base1.0-0 libgtk-3-0 libgtk-3-bin libgtk-3-common
  libharfbuzz0b libhdf4-0-alt libhdf5-103-1 libhdf5-hl-100 libheif1
  libhttp-date-perl libhwloc-plugins libhwloc15 libibverbs1 libicu-dev
  libigdgmm12 libilmbase-dev libilmbase25 libipt2 libjbig-dev libjpeg-dev
  libjpeg-turbo8-dev libjpeg8-dev libjsoncpp25 libkmlbase1 libkmldom1
  libkmlengine1 liblcms2-2 liblept5 libllvm15 liblzma-dev libmfx1 libminizip1
  libmp3lame0 libmpg123-0 libmysqlclient21 libnetcdf19 libnl-route-3-200
  libnorm1 libnspr4 libnss3 libnuma-dev libodbc2 libodbcinst2 libogdi4.1
  libogg0 libopencv-calib3d-dev libopencv-calib3d4.5d libopencv-contrib-dev
  libopencv-contrib4.5d libopencv-core-dev libopencv-core4.5d libopencv-dev
  libopencv-dnn-dev libopencv-dnn4.5d libopencv-features2d-dev
  libopencv-features2d4.5d libopencv-flann-dev libopencv-flann4.5d
  libopencv-highgui-dev libopencv-highgui4.5d libopencv-imgcodecs-dev
  libopencv-imgcodecs4.5d libopencv-imgproc-dev libopencv-imgproc4.5d
  libopencv-ml-dev libopencv-ml4.5d libopencv-objdetect-dev
  libopencv-objdetect4.5d libopencv-photo-dev libopencv-photo4.5d
  libopencv-shape-dev libopencv-shape4.5d libopencv-stitching-dev
  libopencv-stitching4.5d libopencv-superres-dev libopencv-superres4.5d
  libopencv-video-dev libopencv-video4.5d libopencv-videoio-dev
  libopencv-videoio4.5d libopencv-videostab-dev libopencv-videostab4.5d
  libopencv-viz-dev libopencv-viz4.5d libopencv4.5-java libopencv4.5d-jni
  libopenexr-dev libopenexr25 libopengl0 libopenjp2-7 libopenmpi3 libopenmpt0
  libopus0 liborc-0.4-0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0
  libpciaccess-dev libpciaccess0 libpgm-5.3-0 libpixman-1-0 libpmix2
  libpng-dev libpng-tools libpoppler118 libpq5 libproj22 libprotobuf23
  libpsm-infinipath1 libpsm2-2 libpthread-stubs0-dev libqhull-r8.0
  librabbitmq4 libraw1394-11 libraw1394-dev libraw1394-tools librdmacm1
  librsvg2-2 librsvg2-common librttopo1 libsensors-config libsensors5
  libshine3 libsnappy1v5 libsocket++1 libsodium23 libsource-highlight-common
  libsource-highlight4v5 libsoxr0 libspatialite7 libspeex1 libsrt1.4-gnutls
  libssh-gcrypt-4 libstdc++-12-dev libsuperlu5 libswresample-dev
  libswresample3 libswscale-dev libswscale5 libsz2 libtbb-dev libtbb12 libtbb2
  libtbbmalloc2 libtcl8.6 libtesseract4 libthai-data libthai0 libtheora0
  libtiff-dev libtiffxx5 libtimedate-perl libtk8.6 libtwolame0 libucx0
  libudfread0 liburi-perl liburiparser1 libusb-1.0-0 libva-drm2 libva-x11-2
  libva2 libvdpau1 libvisual-0.4-0 libvorbis0a libvorbisenc2 libvorbisfile3
  libvpx7 libvtk9.1 libwayland-client0 libwayland-cursor0 libwayland-egl1
  libwebpmux3 libx11-dev libx11-xcb1 libx264-163 libx265-199 libxau-dev
  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0
  libxcb-render0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1-dev
  libxcomposite1 libxcursor1 libxdamage1 libxdmcp-dev libxerces-c3.2
  libxfixes3 libxft2 libxi6 libxinerama1 libxkbcommon0 libxml2-dev libxnvctrl0
  libxrandr2 libxrender1 libxshmfence1 libxss1 libxtst6 libxvidcore4
  libxxf86vm1 libzmq5 libzvbi-common libzvbi0 mesa-common-dev mesa-va-drivers
  mesa-vdpau-drivers mysql-common ocl-icd-libopencl1 ocl-icd-opencl-dev
  opencl-c-headers opencl-clhpp-headers opencv-data openmp-extras-dev
  openmp-extras-runtime pkg-config poppler-data proj-bin proj-data
  python3-argcomplete rccl rccl-dev rocfft rocfft-dev rocm-cmake rocm-dbgapi
  rocm-debug-agent rocm-developer-tools rocm-gdb rocm-hip-runtime
  rocm-hip-runtime-dev rocm-language-runtime rocm-opencl rocm-opencl-dev
  rocm-opencl-sdk rocm-openmp rocm-smi-lib rocprim-dev rocprofiler
  rocprofiler-compute rocprofiler-dev rocprofiler-plugins rocprofiler-sdk
  rocprofiler-sdk-rocpd rocprofiler-sdk-roctx rocprofiler-systems
  rocthrust-dev roctracer-dev rocwmma-dev rpp rpp-dev session-migration tzdata
  ubuntu-mono unixodbc-common va-driver-all valgrind vdpau-driver-all
  x11-common x11proto-dev xkb-data xorg-sgml-doctools xtrans-dev
Use 'apt autoremove' to remove them.
The following NEW packages will be installed:
  linux-headers-6.5.0-45-generic linux-hwe-6.5-headers-6.5.0-45
The following NEW packages will be installed:
  linux-headers-6.5.0-45-generic linux-hwe-6.5-headers-6.5.0-45
0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.
Need to get 16.7 MB of archives.
After this operation, 112 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-hwe-6.5-headers-6.5.0-45 all 6.5.0-45.45~22.04.1 [13.3 MB]
0 upgraded, 2 newly installed, 0 to remove and 23 not upgraded.
Need to get 16.7 MB of archives.
After this operation, 112 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-hwe-6.5-headers-6.5.0-45 all 6.5.0-45.45~22.04.1 [13.3 MB]
Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-headers-6.5.0-45-generic amd64 6.5.0-45.45~22.04.1 [3426 kB]
Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 linux-headers-6.5.0-45-generic amd64 6.5.0-45.45~22.04.1 [3426 kB]
debconf: delaying package configuration, since apt-utils is not installed
Fetched 16.7 MB in 0s (33.8 MB/s)
Selecting previously unselected package linux-hwe-6.5-headers-6.5.0-45.
debconf: delaying package configuration, since apt-utils is not installed
Fetched 16.7 MB in 1s (30.9 MB/s)
Selecting previously unselected package linux-hwe-6.5-headers-6.5.0-45.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 117257 files and directories currently installed.)
Preparing to unpack .../linux-hwe-6.5-headers-6.5.0-45_6.5.0-45.45~22.04.1_all.deb ...
Unpacking linux-hwe-6.5-headers-6.5.0-45 (6.5.0-45.45~22.04.1) ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 117257 files and directories currently installed.)
Preparing to unpack .../linux-hwe-6.5-headers-6.5.0-45_6.5.0-45.45~22.04.1_all.deb ...
Unpacking linux-hwe-6.5-headers-6.5.0-45 (6.5.0-45.45~22.04.1) ...
Selecting previously unselected package linux-headers-6.5.0-45-generic.
Preparing to unpack .../linux-headers-6.5.0-45-generic_6.5.0-45.45~22.04.1_amd64.deb ...
Unpacking linux-headers-6.5.0-45-generic (6.5.0-45.45~22.04.1) ...
Selecting previously unselected package linux-headers-6.5.0-45-generic.
Preparing to unpack .../linux-headers-6.5.0-45-generic_6.5.0-45.45~22.04.1_amd64.deb ...
Unpacking linux-headers-6.5.0-45-generic (6.5.0-45.45~22.04.1) ...
Setting up linux-hwe-6.5-headers-6.5.0-45 (6.5.0-45.45~22.04.1) ...
Setting up linux-headers-6.5.0-45-generic (6.5.0-45.45~22.04.1) ...
/etc/kernel/header_postinst.d/dkms:
 * dkms: running auto installation service for kernel 6.5.0-45-generic

Kernel preparation unnecessary for this kernel. Skipping...
Setting up linux-hwe-6.5-headers-6.5.0-45 (6.5.0-45.45~22.04.1) ...
Setting up linux-headers-6.5.0-45-generic (6.5.0-45.45~22.04.1) ...
/etc/kernel/header_postinst.d/dkms:
 * dkms: running auto installation service for kernel 6.5.0-45-generic

Kernel preparation unnecessary for this kernel. Skipping...

Building module:
cleaning build area...(bad exit status: 2)

Building module:
cleaning build area...(bad exit status: 2)
'make' KERNELVER=6.5.0-45-generic.........
'make' KERNELVER=6.5.0-45-generic.........
cleaning build area...
Forcing installation of amdgpu

amdgpu.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdttm.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdkcl.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amd-sched.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_ttm_helper.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_buddy.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_exec.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdxcp.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

depmod...
   ...done.

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

cleaning build area...
Forcing installation of amdgpu

amdgpu.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdttm.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdkcl.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amd-sched.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_ttm_helper.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_buddy.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amddrm_exec.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

amdxcp.ko:
Running module version sanity check.
 - Original module
   - No original module exists within this kernel
 - Installation
   - Installing to /lib/modules/6.5.0-45-generic/updates/dkms/

depmod...
   ...done.

WARNING: apt does not have a stable CLI interface. Use with caution in scripts.

Reading package lists...
Building dependency tree...
Reading state information...
autoconf is already the newest version (2.71-2).
gcc is already the newest version (4:11.2.0-1ubuntu1).
gcc set to manually installed.
libtool is already the newest version (2.4.6-15build2).
make is already the newest version (4.3-4.1build1).
make set to manually installed.
rdma-core is already the newest version (39.0-1).
ethtool is already the newest version (1:5.16-1ubuntu0.2).
ethtool set to manually installed.
The following packages were automatically installed and are no longer required:
  adwaita-icon-theme amd-smi-lib at-spi2-core composablekernel-dev
  dbus-user-session dconf-gsettings-backend dconf-service fontconfig gdal-data
  gdb gsettings-desktop-schemas gstreamer1.0-plugins-base
  gtk-update-icon-cache half hicolor-icon-theme hip-dev hip-doc hip-samples
  hipcc hipcub-dev hipfft hipfft-dev hipfort-dev hipify-clang hiprand
  hiprand-dev hipsparse hipsparse-dev hipsparselt hipsparselt-dev hiptensor
  hiptensor-dev hsa-amd-aqlprofile hsa-rocr-dev humanity-icon-theme
  i965-va-driver icu-devtools intel-media-va-driver libaacs0 libaec0 libaom3
  libarchive13 libarmadillo10 libarpack2 libatk-bridge2.0-0 libatk1.0-0
  libatk1.0-data libatspi2.0-0 libavahi-client3 libavahi-common-data
  libavahi-common3 libavcodec-dev libavcodec58 libavformat-dev libavformat58
  libavutil-dev libavutil56 libbabeltrace1 libbdplus0 libblosc1 libbluray2
  libboost-regex1.74.0 libc6-dbg libcairo-gobject2 libcairo2 libcdparanoia0
  libcfitsio9 libcharls2 libchromaprint1 libcodec2-1.0 libcolord2 libcups2
  libdatrie1 libdav1d5 libdc1394-25 libdc1394-dev libdconf1 libde265-0
  libdebuginfod-common libdebuginfod1 libdeflate-dev libdouble-conversion3
  libdrm-amdgpu-dev libdrm-amdgpu-radeon1 libdrm-dev libdrm-intel1
  libdrm-nouveau2 libdrm-radeon1 libepoxy0 libevent-core-2.1-7
  libevent-pthreads-2.1-7 libexif-dev libexif-doc libexif12 libfabric1
  libfile-copy-recursive-perl libfile-listing-perl libfile-which-perl
  libfreexl1 libfribidi0 libfyba0 libgdal30 libgdcm-dev libgdcm3.0
  libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common
  libgeos-c1v5 libgeos3.10.2 libgeotiff5 libgif7 libgl-dev libgl1
  libgl1-amber-dri libgl1-mesa-dri libgl2ps1.4 libglapi-mesa libglew2.2
  libglvnd0 libglx-dev libglx-mesa0 libglx0 libgme0 libgphoto2-6
  libgphoto2-dev libgphoto2-l10n libgphoto2-port12 libgraphite2-3 libgsm1
  libgstreamer-plugins-base1.0-0 libgtk-3-0 libgtk-3-bin libgtk-3-common
  libharfbuzz0b libhdf4-0-alt libhdf5-103-1 libhdf5-hl-100 libheif1
  libhttp-date-perl libhwloc-plugins libhwloc15 libicu-dev libigdgmm12
  libilmbase-dev libilmbase25 libipt2 libjbig-dev libjpeg-dev
  libjpeg-turbo8-dev libjpeg8-dev libjsoncpp25 libkmlbase1 libkmldom1
  libkmlengine1 liblcms2-2 liblept5 libllvm15 liblzma-dev libmfx1 libminizip1
  libmp3lame0 libmpg123-0 libmysqlclient21 libnetcdf19 libnorm1 libnspr4
  libnss3 libnuma-dev libodbc2 libodbcinst2 libogdi4.1 libogg0
  libopencv-calib3d-dev libopencv-calib3d4.5d libopencv-contrib-dev
  libopencv-contrib4.5d libopencv-core-dev libopencv-core4.5d libopencv-dev
  libopencv-dnn-dev libopencv-dnn4.5d libopencv-features2d-dev
  libopencv-features2d4.5d libopencv-flann-dev libopencv-flann4.5d
  libopencv-highgui-dev libopencv-highgui4.5d libopencv-imgcodecs-dev
  libopencv-imgcodecs4.5d libopencv-imgproc-dev libopencv-imgproc4.5d
  libopencv-ml-dev libopencv-ml4.5d libopencv-objdetect-dev
  libopencv-objdetect4.5d libopencv-photo-dev libopencv-photo4.5d
  libopencv-shape-dev libopencv-shape4.5d libopencv-stitching-dev
  libopencv-stitching4.5d libopencv-superres-dev libopencv-superres4.5d
  libopencv-video-dev libopencv-video4.5d libopencv-videoio-dev
  libopencv-videoio4.5d libopencv-videostab-dev libopencv-videostab4.5d
  libopencv-viz-dev libopencv-viz4.5d libopencv4.5-java libopencv4.5d-jni
  libopenexr-dev libopenexr25 libopengl0 libopenjp2-7 libopenmpi3 libopenmpt0
  libopus0 liborc-0.4-0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0
  libpciaccess-dev libpciaccess0 libpgm-5.3-0 libpixman-1-0 libpmix2
  libpng-dev libpng-tools libpoppler118 libpq5 libproj22 libprotobuf23
  libpsm-infinipath1 libpsm2-2 libpthread-stubs0-dev libqhull-r8.0
  librabbitmq4 libraw1394-11 libraw1394-dev libraw1394-tools librsvg2-2
  librsvg2-common librttopo1 libsensors-config libsensors5 libshine3
  libsnappy1v5 libsocket++1 libsodium23 libsource-highlight-common
  libsource-highlight4v5 libsoxr0 libspatialite7 libspeex1 libsrt1.4-gnutls
  libssh-gcrypt-4 libstdc++-12-dev libsuperlu5 libswresample-dev
  libswresample3 libswscale-dev libswscale5 libsz2 libtbb-dev libtbb12 libtbb2
  libtbbmalloc2 libtcl8.6 libtesseract4 libthai-data libthai0 libtheora0
  libtiff-dev libtiffxx5 libtimedate-perl libtk8.6 libtwolame0 libucx0
  libudfread0 liburi-perl liburiparser1 libusb-1.0-0 libva-drm2 libva-x11-2
  libva2 libvdpau1 libvisual-0.4-0 libvorbis0a libvorbisenc2 libvorbisfile3
  libvpx7 libvtk9.1 libwayland-client0 libwayland-cursor0 libwayland-egl1
  libwebpmux3 libx11-dev libx11-xcb1 libx264-163 libx265-199 libxau-dev
  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0
  libxcb-render0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1-dev
  libxcomposite1 libxcursor1 libxdamage1 libxdmcp-dev libxerces-c3.2
  libxfixes3 libxft2 libxi6 libxinerama1 libxkbcommon0 libxml2-dev libxnvctrl0
  libxrandr2 libxrender1 libxshmfence1 libxss1 libxtst6 libxvidcore4
  libxxf86vm1 libzmq5 libzvbi-common libzvbi0 mesa-common-dev mesa-va-drivers
  mesa-vdpau-drivers mysql-common ocl-icd-libopencl1 ocl-icd-opencl-dev
  opencl-c-headers opencl-clhpp-headers opencv-data openmp-extras-dev
  openmp-extras-runtime pkg-config poppler-data proj-bin proj-data
  python3-argcomplete rccl rccl-dev rocfft rocfft-dev rocm-cmake rocm-dbgapi
  rocm-debug-agent rocm-developer-tools rocm-gdb rocm-hip-runtime
  rocm-hip-runtime-dev rocm-language-runtime rocm-opencl rocm-opencl-dev
  rocm-opencl-sdk rocm-openmp rocm-smi-lib rocprim-dev rocprofiler
  rocprofiler-compute rocprofiler-dev rocprofiler-plugins rocprofiler-sdk
  rocprofiler-sdk-rocpd rocprofiler-sdk-roctx rocprofiler-systems
  rocthrust-dev roctracer-dev rocwmma-dev rpp rpp-dev session-migration tzdata
  ubuntu-mono unixodbc-common va-driver-all valgrind vdpau-driver-all
  x11-common x11proto-dev xkb-data xorg-sgml-doctools xtrans-dev
Use 'apt autoremove' to remove them.
The following additional packages will be installed:
  libibmad5 libibnetdisc5 libibumad3 libnl-3-dev libnl-route-3-dev
The following NEW packages will be installed:
  ibverbs-utils infiniband-diags libibmad5 libibnetdisc5 libibumad3
  libibverbs-dev libnl-3-dev libnl-route-3-dev librdmacm-dev perftest
  rdmacm-utils strace
Reading package lists...
Building dependency tree...
Reading state information...
0 upgraded, 12 newly installed, 0 to remove and 23 not upgraded.
Need to get 2318 kB of archives.
After this operation, 11.0 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 strace amd64 5.16-0ubuntu3 [567 kB]
autoconf is already the newest version (2.71-2).
gcc is already the newest version (4:11.2.0-1ubuntu1).
gcc set to manually installed.
libtool is already the newest version (2.4.6-15build2).
make is already the newest version (4.3-4.1build1).
make set to manually installed.
rdma-core is already the newest version (39.0-1).
ethtool is already the newest version (1:5.16-1ubuntu0.2).
ethtool set to manually installed.
The following packages were automatically installed and are no longer required:
  adwaita-icon-theme amd-smi-lib at-spi2-core composablekernel-dev
  dbus-user-session dconf-gsettings-backend dconf-service fontconfig gdal-data
  gdb gsettings-desktop-schemas gstreamer1.0-plugins-base
  gtk-update-icon-cache half hicolor-icon-theme hip-dev hip-doc hip-samples
  hipcc hipcub-dev hipfft hipfft-dev hipfort-dev hipify-clang hiprand
  hiprand-dev hipsparse hipsparse-dev hipsparselt hipsparselt-dev hiptensor
  hiptensor-dev hsa-amd-aqlprofile hsa-rocr-dev humanity-icon-theme
  i965-va-driver icu-devtools intel-media-va-driver libaacs0 libaec0 libaom3
  libarchive13 libarmadillo10 libarpack2 libatk-bridge2.0-0 libatk1.0-0
  libatk1.0-data libatspi2.0-0 libavahi-client3 libavahi-common-data
  libavahi-common3 libavcodec-dev libavcodec58 libavformat-dev libavformat58
  libavutil-dev libavutil56 libbabeltrace1 libbdplus0 libblosc1 libbluray2
  libboost-regex1.74.0 libc6-dbg libcairo-gobject2 libcairo2 libcdparanoia0
  libcfitsio9 libcharls2 libchromaprint1 libcodec2-1.0 libcolord2 libcups2
  libdatrie1 libdav1d5 libdc1394-25 libdc1394-dev libdconf1 libde265-0
  libdebuginfod-common libdebuginfod1 libdeflate-dev libdouble-conversion3
  libdrm-amdgpu-dev libdrm-amdgpu-radeon1 libdrm-dev libdrm-intel1
  libdrm-nouveau2 libdrm-radeon1 libepoxy0 libevent-core-2.1-7
  libevent-pthreads-2.1-7 libexif-dev libexif-doc libexif12 libfabric1
  libfile-copy-recursive-perl libfile-listing-perl libfile-which-perl
  libfreexl1 libfribidi0 libfyba0 libgdal30 libgdcm-dev libgdcm3.0
  libgdk-pixbuf-2.0-0 libgdk-pixbuf2.0-bin libgdk-pixbuf2.0-common
  libgeos-c1v5 libgeos3.10.2 libgeotiff5 libgif7 libgl-dev libgl1
  libgl1-amber-dri libgl1-mesa-dri libgl2ps1.4 libglapi-mesa libglew2.2
  libglvnd0 libglx-dev libglx-mesa0 libglx0 libgme0 libgphoto2-6
  libgphoto2-dev libgphoto2-l10n libgphoto2-port12 libgraphite2-3 libgsm1
  libgstreamer-plugins-base1.0-0 libgtk-3-0 libgtk-3-bin libgtk-3-common
  libharfbuzz0b libhdf4-0-alt libhdf5-103-1 libhdf5-hl-100 libheif1
  libhttp-date-perl libhwloc-plugins libhwloc15 libicu-dev libigdgmm12
  libilmbase-dev libilmbase25 libipt2 libjbig-dev libjpeg-dev
  libjpeg-turbo8-dev libjpeg8-dev libjsoncpp25 libkmlbase1 libkmldom1
  libkmlengine1 liblcms2-2 liblept5 libllvm15 liblzma-dev libmfx1 libminizip1
  libmp3lame0 libmpg123-0 libmysqlclient21 libnetcdf19 libnorm1 libnspr4
  libnss3 libnuma-dev libodbc2 libodbcinst2 libogdi4.1 libogg0
  libopencv-calib3d-dev libopencv-calib3d4.5d libopencv-contrib-dev
  libopencv-contrib4.5d libopencv-core-dev libopencv-core4.5d libopencv-dev
  libopencv-dnn-dev libopencv-dnn4.5d libopencv-features2d-dev
  libopencv-features2d4.5d libopencv-flann-dev libopencv-flann4.5d
  libopencv-highgui-dev libopencv-highgui4.5d libopencv-imgcodecs-dev
  libopencv-imgcodecs4.5d libopencv-imgproc-dev libopencv-imgproc4.5d
  libopencv-ml-dev libopencv-ml4.5d libopencv-objdetect-dev
  libopencv-objdetect4.5d libopencv-photo-dev libopencv-photo4.5d
  libopencv-shape-dev libopencv-shape4.5d libopencv-stitching-dev
  libopencv-stitching4.5d libopencv-superres-dev libopencv-superres4.5d
  libopencv-video-dev libopencv-video4.5d libopencv-videoio-dev
  libopencv-videoio4.5d libopencv-videostab-dev libopencv-videostab4.5d
  libopencv-viz-dev libopencv-viz4.5d libopencv4.5-java libopencv4.5d-jni
  libopenexr-dev libopenexr25 libopengl0 libopenjp2-7 libopenmpi3 libopenmpt0
  libopus0 liborc-0.4-0 libpango-1.0-0 libpangocairo-1.0-0 libpangoft2-1.0-0
  libpciaccess-dev libpciaccess0 libpgm-5.3-0 libpixman-1-0 libpmix2
  libpng-dev libpng-tools libpoppler118 libpq5 libproj22 libprotobuf23
  libpsm-infinipath1 libpsm2-2 libpthread-stubs0-dev libqhull-r8.0
  librabbitmq4 libraw1394-11 libraw1394-dev libraw1394-tools librsvg2-2
  librsvg2-common librttopo1 libsensors-config libsensors5 libshine3
  libsnappy1v5 libsocket++1 libsodium23 libsource-highlight-common
  libsource-highlight4v5 libsoxr0 libspatialite7 libspeex1 libsrt1.4-gnutls
  libssh-gcrypt-4 libstdc++-12-dev libsuperlu5 libswresample-dev
  libswresample3 libswscale-dev libswscale5 libsz2 libtbb-dev libtbb12 libtbb2
  libtbbmalloc2 libtcl8.6 libtesseract4 libthai-data libthai0 libtheora0
  libtiff-dev libtiffxx5 libtimedate-perl libtk8.6 libtwolame0 libucx0
  libudfread0 liburi-perl liburiparser1 libusb-1.0-0 libva-drm2 libva-x11-2
  libva2 libvdpau1 libvisual-0.4-0 libvorbis0a libvorbisenc2 libvorbisfile3
  libvpx7 libvtk9.1 libwayland-client0 libwayland-cursor0 libwayland-egl1
  libwebpmux3 libx11-dev libx11-xcb1 libx264-163 libx265-199 libxau-dev
  libxcb-dri2-0 libxcb-dri3-0 libxcb-glx0 libxcb-present0 libxcb-randr0
  libxcb-render0 libxcb-shm0 libxcb-sync1 libxcb-xfixes0 libxcb1-dev
  libxcomposite1 libxcursor1 libxdamage1 libxdmcp-dev libxerces-c3.2
  libxfixes3 libxft2 libxi6 libxinerama1 libxkbcommon0 libxml2-dev libxnvctrl0
  libxrandr2 libxrender1 libxshmfence1 libxss1 libxtst6 libxvidcore4
  libxxf86vm1 libzmq5 libzvbi-common libzvbi0 mesa-common-dev mesa-va-drivers
  mesa-vdpau-drivers mysql-common ocl-icd-libopencl1 ocl-icd-opencl-dev
  opencl-c-headers opencl-clhpp-headers opencv-data openmp-extras-dev
  openmp-extras-runtime pkg-config poppler-data proj-bin proj-data
  python3-argcomplete rccl rccl-dev rocfft rocfft-dev rocm-cmake rocm-dbgapi
  rocm-debug-agent rocm-developer-tools rocm-gdb rocm-hip-runtime
  rocm-hip-runtime-dev rocm-language-runtime rocm-opencl rocm-opencl-dev
  rocm-opencl-sdk rocm-openmp rocm-smi-lib rocprim-dev rocprofiler
  rocprofiler-compute rocprofiler-dev rocprofiler-plugins rocprofiler-sdk
  rocprofiler-sdk-rocpd rocprofiler-sdk-roctx rocprofiler-systems
  rocthrust-dev roctracer-dev rocwmma-dev rpp rpp-dev session-migration tzdata
  ubuntu-mono unixodbc-common va-driver-all valgrind vdpau-driver-all
  x11-common x11proto-dev xkb-data xorg-sgml-doctools xtrans-dev
Use 'apt autoremove' to remove them.
The following additional packages will be installed:
  libibmad5 libibnetdisc5 libibumad3 libnl-3-dev libnl-route-3-dev
The following NEW packages will be installed:
  ibverbs-utils infiniband-diags libibmad5 libibnetdisc5 libibumad3
  libibverbs-dev libnl-3-dev libnl-route-3-dev librdmacm-dev perftest
  rdmacm-utils strace
0 upgraded, 12 newly installed, 0 to remove and 23 not upgraded.
Need to get 2318 kB of archives.
After this operation, 11.0 MB of additional disk space will be used.
Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 strace amd64 5.16-0ubuntu3 [567 kB]
Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-3-dev amd64 3.5.0-0.1 [101 kB]
Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-route-3-dev amd64 3.5.0-0.1 [202 kB]
Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ibverbs-utils amd64 39.0-1 [57.3 kB]
Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibumad3 amd64 39.0-1 [28.4 kB]
Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibmad5 amd64 39.0-1 [43.7 kB]
Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibnetdisc5 amd64 39.0-1 [32.6 kB]
Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 infiniband-diags amd64 39.0-1 [235 kB]
Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibverbs-dev amd64 39.0-1 [628 kB]
Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 librdmacm-dev amd64 39.0-1 [129 kB]
Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 perftest amd64 4.4+0.37-1 [219 kB]
Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 rdmacm-utils amd64 39.0-1 [74.6 kB]
debconf: delaying package configuration, since apt-utils is not installed
Fetched 2318 kB in 0s (9507 kB/s)
Selecting previously unselected package strace.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 147145 files and directories currently installed.)
Preparing to unpack .../00-strace_5.16-0ubuntu3_amd64.deb ...
Unpacking strace (5.16-0ubuntu3) ...
Selecting previously unselected package libnl-3-dev:amd64.
Preparing to unpack .../01-libnl-3-dev_3.5.0-0.1_amd64.deb ...
Unpacking libnl-3-dev:amd64 (3.5.0-0.1) ...
Selecting previously unselected package libnl-route-3-dev:amd64.
Preparing to unpack .../02-libnl-route-3-dev_3.5.0-0.1_amd64.deb ...
Unpacking libnl-route-3-dev:amd64 (3.5.0-0.1) ...
Selecting previously unselected package ibverbs-utils.
Preparing to unpack .../03-ibverbs-utils_39.0-1_amd64.deb ...
Unpacking ibverbs-utils (39.0-1) ...
Selecting previously unselected package libibumad3:amd64.
Preparing to unpack .../04-libibumad3_39.0-1_amd64.deb ...
Unpacking libibumad3:amd64 (39.0-1) ...
Selecting previously unselected package libibmad5:amd64.
Preparing to unpack .../05-libibmad5_39.0-1_amd64.deb ...
Unpacking libibmad5:amd64 (39.0-1) ...
Selecting previously unselected package libibnetdisc5:amd64.
Preparing to unpack .../06-libibnetdisc5_39.0-1_amd64.deb ...
Unpacking libibnetdisc5:amd64 (39.0-1) ...
Selecting previously unselected package infiniband-diags.
Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-3-dev amd64 3.5.0-0.1 [101 kB]
Preparing to unpack .../07-infiniband-diags_39.0-1_amd64.deb ...
Unpacking infiniband-diags (39.0-1) ...
Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-route-3-dev amd64 3.5.0-0.1 [202 kB]
Selecting previously unselected package libibverbs-dev:amd64.
Preparing to unpack .../08-libibverbs-dev_39.0-1_amd64.deb ...
Unpacking libibverbs-dev:amd64 (39.0-1) ...
Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ibverbs-utils amd64 39.0-1 [57.3 kB]
Selecting previously unselected package librdmacm-dev:amd64.
Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibumad3 amd64 39.0-1 [28.4 kB]
Preparing to unpack .../09-librdmacm-dev_39.0-1_amd64.deb ...
Unpacking librdmacm-dev:amd64 (39.0-1) ...
Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibmad5 amd64 39.0-1 [43.7 kB]
Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibnetdisc5 amd64 39.0-1 [32.6 kB]
Selecting previously unselected package perftest.
Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 infiniband-diags amd64 39.0-1 [235 kB]
Preparing to unpack .../10-perftest_4.4+0.37-1_amd64.deb ...
Unpacking perftest (4.4+0.37-1) ...
Selecting previously unselected package rdmacm-utils.
Preparing to unpack .../11-rdmacm-utils_39.0-1_amd64.deb ...
Unpacking rdmacm-utils (39.0-1) ...
Setting up libibumad3:amd64 (39.0-1) ...
Setting up libibmad5:amd64 (39.0-1) ...
Setting up ibverbs-utils (39.0-1) ...
Setting up strace (5.16-0ubuntu3) ...
Setting up libibnetdisc5:amd64 (39.0-1) ...
Setting up libnl-3-dev:amd64 (3.5.0-0.1) ...
Setting up rdmacm-utils (39.0-1) ...
Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libibverbs-dev amd64 39.0-1 [628 kB]
Setting up infiniband-diags (39.0-1) ...
Setting up perftest (4.4+0.37-1) ...
Setting up libnl-route-3-dev:amd64 (3.5.0-0.1) ...
Setting up libibverbs-dev:amd64 (39.0-1) ...
Setting up librdmacm-dev:amd64 (39.0-1) ...
Processing triggers for libc-bin (2.35-0ubuntu3.10) ...
Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 librdmacm-dev amd64 39.0-1 [129 kB]
Get:11 http://archive.ubuntu.com/ubuntu jammy/universe amd64 perftest amd64 4.4+0.37-1 [219 kB]
Get:12 http://archive.ubuntu.com/ubuntu jammy/universe amd64 rdmacm-utils amd64 39.0-1 [74.6 kB]
+ aclocal -I config
debconf: delaying package configuration, since apt-utils is not installed
Fetched 2318 kB in 1s (2372 kB/s)
Selecting previously unselected package strace.
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 147145 files and directories currently installed.)
Preparing to unpack .../00-strace_5.16-0ubuntu3_amd64.deb ...
Unpacking strace (5.16-0ubuntu3) ...
Selecting previously unselected package libnl-3-dev:amd64.
Preparing to unpack .../01-libnl-3-dev_3.5.0-0.1_amd64.deb ...
Unpacking libnl-3-dev:amd64 (3.5.0-0.1) ...
Selecting previously unselected package libnl-route-3-dev:amd64.
Preparing to unpack .../02-libnl-route-3-dev_3.5.0-0.1_amd64.deb ...
Unpacking libnl-route-3-dev:amd64 (3.5.0-0.1) ...
Selecting previously unselected package ibverbs-utils.
Preparing to unpack .../03-ibverbs-utils_39.0-1_amd64.deb ...
Unpacking ibverbs-utils (39.0-1) ...
Selecting previously unselected package libibumad3:amd64.
Preparing to unpack .../04-libibumad3_39.0-1_amd64.deb ...
Unpacking libibumad3:amd64 (39.0-1) ...
Selecting previously unselected package libibmad5:amd64.
Preparing to unpack .../05-libibmad5_39.0-1_amd64.deb ...
Unpacking libibmad5:amd64 (39.0-1) ...
Selecting previously unselected package libibnetdisc5:amd64.
Preparing to unpack .../06-libibnetdisc5_39.0-1_amd64.deb ...
Unpacking libibnetdisc5:amd64 (39.0-1) ...
Selecting previously unselected package infiniband-diags.
Preparing to unpack .../07-infiniband-diags_39.0-1_amd64.deb ...
Unpacking infiniband-diags (39.0-1) ...
Selecting previously unselected package libibverbs-dev:amd64.
Preparing to unpack .../08-libibverbs-dev_39.0-1_amd64.deb ...
Unpacking libibverbs-dev:amd64 (39.0-1) ...
Selecting previously unselected package librdmacm-dev:amd64.
Preparing to unpack .../09-librdmacm-dev_39.0-1_amd64.deb ...
Unpacking librdmacm-dev:amd64 (39.0-1) ...
Selecting previously unselected package perftest.
Preparing to unpack .../10-perftest_4.4+0.37-1_amd64.deb ...
Unpacking perftest (4.4+0.37-1) ...
Selecting previously unselected package rdmacm-utils.
Preparing to unpack .../11-rdmacm-utils_39.0-1_amd64.deb ...
Unpacking rdmacm-utils (39.0-1) ...
Setting up libibumad3:amd64 (39.0-1) ...
Setting up libibmad5:amd64 (39.0-1) ...
Setting up ibverbs-utils (39.0-1) ...
Setting up strace (5.16-0ubuntu3) ...
Setting up libibnetdisc5:amd64 (39.0-1) ...
Setting up libnl-3-dev:amd64 (3.5.0-0.1) ...
Setting up rdmacm-utils (39.0-1) ...
Setting up infiniband-diags (39.0-1) ...
Setting up perftest (4.4+0.37-1) ...
Setting up libnl-route-3-dev:amd64 (3.5.0-0.1) ...
Setting up libibverbs-dev:amd64 (39.0-1) ...
Setting up librdmacm-dev:amd64 (39.0-1) ...
Processing triggers for libc-bin (2.35-0ubuntu3.10) ...
+ aclocal -I config
+ libtoolize --force --copy
+ libtoolize --force --copy
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
libtoolize: copying file 'config/ltmain.sh'
libtoolize: putting macros in 'm4'.
libtoolize: copying file 'm4/libtool.m4'
libtoolize: putting auxiliary files in AC_CONFIG_AUX_DIR, 'config'.
libtoolize: copying file 'config/ltmain.sh'
libtoolize: copying file 'm4/ltoptions.m4'
libtoolize: copying file 'm4/ltsugar.m4'
libtoolize: copying file 'm4/ltversion.m4'
libtoolize: copying file 'm4/lt~obsolete.m4'
libtoolize: Consider adding 'AC_CONFIG_MACRO_DIRS([m4])' to configure.ac,
libtoolize: and rerunning libtoolize and aclocal.
+ autoheader
libtoolize: putting macros in 'm4'.
libtoolize: copying file 'm4/libtool.m4'
libtoolize: copying file 'm4/ltoptions.m4'
libtoolize: copying file 'm4/ltsugar.m4'
libtoolize: copying file 'm4/ltversion.m4'
libtoolize: copying file 'm4/lt~obsolete.m4'
+ automake --foreign --add-missing --copy
libtoolize: Consider adding 'AC_CONFIG_MACRO_DIRS([m4])' to configure.ac,
libtoolize: and rerunning libtoolize and aclocal.
+ autoheader
configure.ac:26: installing 'config/compile'
configure.ac:25: installing 'config/missing'
Makefile.am: installing 'config/depcomp'
+ autoconf -f
+ automake --foreign --add-missing --copy
configure.ac:26: installing 'config/compile'
configure.ac:25: installing 'config/missing'
Makefile.am: installing 'config/depcomp'
+ autoconf -f
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a race-free mkdir -p... /usr/bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking how to print strings... printf
checking whether make supports the include directive... yes (GNU style)
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether the compiler supports GNU C... yes
checking whether gcc accepts -g... yes
checking for gcc option to enable C11 features... none needed
checking whether gcc understands -c and -o together... yes
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 1572864
checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... no
checking how to associate runtime and link libraries... printf %s\n
checking for ar... ar
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /usr/bin/dd
checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
checking for mt... mt
checking if mt is a manifest tool... no
checking for stdio.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for inttypes.h... yes
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a race-free mkdir -p... /usr/bin/mkdir -p
checking for gawk... no
checking for mawk... mawk
checking for stdint.h... yes
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking for strings.h... yes
checking for sys/stat.h... yes
checking for sys/types.h... yes
checking build system type... x86_64-unknown-linux-gnu
checking host system type... x86_64-unknown-linux-gnu
checking how to print strings... printf
checking whether make supports the include directive... yes (GNU style)
checking for gcc... gcc
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether the compiler supports GNU C... yes
checking whether gcc accepts -g... yes
checking if gcc static flag -static works... yes
checking for gcc option to enable C11 features... none needed
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether gcc understands -c and -o together... yes
checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc... /usr/bin/ld
checking if the linker (/usr/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 1572864
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop
checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop
checking for /usr/bin/ld option to reload object files... -r
checking for objdump... objdump
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking how to recognize dependent libraries... pass_all
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking for dlltool... no
checking how to associate runtime and link libraries... printf %s\n
checking for ar... ar
checking for gcc... (cached) gcc
checking for archiver @FILE support... @
checking for strip... strip
checking for ranlib... ranlib
checking whether the compiler supports GNU C... (cached) yes
checking whether gcc accepts -g... (cached) yes
checking for gcc option to enable C11 features... (cached) none needed
checking whether gcc understands -c and -o together... (cached) yes
checking dependency style of gcc... (cached) gcc3
checking size of long... 8
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /usr/bin/dd
checking how to truncate binary pipes... /usr/bin/dd bs=4096 count=1
checking for mt... mt
checking for ibv_get_device_list in -libverbs... yes
checking if mt is a manifest tool... no
checking for stdio.h... yes
checking for sysfs/libsysfs.h... no
checking for stdlib.h... yes
checking for string.h... yes
checking for infiniband/verbs.h... yes
checking for rdma-core framework usage... yes using v39/v40/v41/v42/v43
checking for inttypes.h... (cached) yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for locale.h... yes
checking for strings.h... yes
checking for stddef.h... yes
checking for stdint.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking for sys/stat.h... yes
checking for sys/types.h... yes
checking for new definition of struct ibv_send_wr... yes
checking for unistd.h... yes
checking for send-with-invalidate opcode support... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking for local-invalidate opcode support... yes
checking check for ib_uverbs_flow_spec_action_handle defined... yes
yes
checking check if ib_uverbs_cq_moderation is defined... yes
checking check if ib_uverbs_ex_modify_cq is defined... yes
checking for sched_yield defined... yes
checking for disabling data path spin lock... no
checking for enabling deferred arming logic... no
checking for enabling deferred db logic... no
checking for enabling dev debug logic... no
checking for compile time macro definitions... yes
checking size of long... (cached) 8
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking for bnxt_re.driver file... yes
checking whether ld accepts --version-script... yes
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/bin/ld -m elf_x86_64) supports shared libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... GNU/Linux ld.so
checking how to hardcode library paths into programs... immediate
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking for gcc... (cached) gcc
checking whether the compiler supports GNU C... (cached) yes
checking whether gcc accepts -g... (cached) yes
checking for gcc option to enable C11 features... (cached) none needed
checking whether gcc understands -c and -o together... (cached) yes
checking dependency style of gcc... (cached) gcc3
checking size of long... 8
checking for ibv_get_device_list in -libverbs... yes
checking for sysfs/libsysfs.h... no
checking for infiniband/verbs.h... yes
checking for rdma-core framework usage... yes using v39/v40/v41/v42/v43
checking for inttypes.h... (cached) yes
checking for locale.h... yes
checking that generated files are newer than configure... done
configure: creating ./config.status
checking for stddef.h... yes
checking for stdint.h... (cached) yes
checking for an ANSI C-conforming const... yes
checking for new definition of struct ibv_send_wr... yes
checking for send-with-invalidate opcode support... yes
checking for local-invalidate opcode support... yes
checking check for ib_uverbs_flow_spec_action_handle defined... yes
yes
checking check if ib_uverbs_cq_moderation is defined... yes
checking check if ib_uverbs_ex_modify_cq is defined... yes
checking for sched_yield defined... yes
checking for disabling data path spin lock... no
checking for enabling deferred arming logic... no
checking for enabling deferred db logic... no
checking for enabling dev debug logic... no
checking for compile time macro definitions... yes
checking size of long... (cached) 8
checking for bnxt_re.driver file... yes
checking whether ld accepts --version-script... yes
config.status: creating Makefile
config.status: creating libbnxt.spec
config.status: creating config.h
config.status: executing depfiles commands
config.status: executing libtool commands
checking that generated files are newer than configure... done
configure: creating ./config.status
make: Entering directory '/tmp/libbnxt'
test -z "src/libbnxt_re.la" || rm -f src/libbnxt_re.la
rm -f src/so_locations
rm -rf .libs _libs
rm -rf src/.libs src/_libs
rm -f *.o
rm -f src/*.o
rm -f src/*.lo
rm -f *.lo
make  all-am
make[1]: Entering directory '/tmp/libbnxt'
depbase=`echo src/main.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF $depbase.Tpo -c -o src/main.lo src/main.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF src/.deps/main.Tpo -c src/main.c  -fPIC -DPIC -o src/.libs/main.o
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF src/.deps/main.Tpo -c src/main.c -o src/main.o >/dev/null 2>&1
depbase=`echo src/verbs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF $depbase.Tpo -c -o src/verbs.lo src/verbs.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF src/.deps/verbs.Tpo -c src/verbs.c  -fPIC -DPIC -o src/.libs/verbs.o
config.status: creating Makefile
config.status: creating libbnxt.spec
config.status: creating config.h
config.status: executing depfiles commands
config.status: executing libtool commands
make: Entering directory '/tmp/libbnxt'
test -z "src/libbnxt_re.la" || rm -f src/libbnxt_re.la
rm -f src/so_locations
rm -rf .libs _libs
rm -rf src/.libs src/_libs
rm -f *.o
rm -f src/*.o
rm -f src/*.lo
rm -f *.lo
make  all-am
make[1]: Entering directory '/tmp/libbnxt'
depbase=`echo src/main.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF $depbase.Tpo -c -o src/main.lo src/main.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF src/.deps/main.Tpo -c src/main.c  -fPIC -DPIC -o src/.libs/main.o
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/main.lo -MD -MP -MF src/.deps/main.Tpo -c src/main.c -o src/main.o >/dev/null 2>&1
depbase=`echo src/verbs.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF $depbase.Tpo -c -o src/verbs.lo src/verbs.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF src/.deps/verbs.Tpo -c src/verbs.c  -fPIC -DPIC -o src/.libs/verbs.o
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF src/.deps/verbs.Tpo -c src/verbs.c -o src/verbs.o >/dev/null 2>&1
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/verbs.lo -MD -MP -MF src/.deps/verbs.Tpo -c src/verbs.c -o src/verbs.o >/dev/null 2>&1
depbase=`echo src/memory.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF $depbase.Tpo -c -o src/memory.lo src/memory.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF src/.deps/memory.Tpo -c src/memory.c  -fPIC -DPIC -o src/.libs/memory.o
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF src/.deps/memory.Tpo -c src/memory.c -o src/memory.o >/dev/null 2>&1
depbase=`echo src/db.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF $depbase.Tpo -c -o src/db.lo src/db.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF src/.deps/db.Tpo -c src/db.c  -fPIC -DPIC -o src/.libs/db.o
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF src/.deps/db.Tpo -c src/db.c -o src/db.o >/dev/null 2>&1
depbase=`echo src/memory.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF $depbase.Tpo -c -o src/memory.lo src/memory.c &&\
mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF src/.deps/memory.Tpo -c src/memory.c  -fPIC -DPIC -o src/.libs/memory.o
/bin/bash ./libtool  --tag=CC   --mode=link gcc -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -avoid-version -module -release rdmav34 -Wl,--version-script=./src/bnxt_re.map  -o src/libbnxt_re.la -rpath /usr/local/lib src/main.lo src/verbs.lo src/memory.lo src/db.lo   -lm -libverbs 
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/memory.lo -MD -MP -MF src/.deps/memory.Tpo -c src/memory.c -o src/memory.o >/dev/null 2>&1
libtool: link: gcc -shared  -fPIC -DPIC  src/.libs/main.o src/.libs/verbs.o src/.libs/memory.o src/.libs/db.o   -lm -libverbs  -g -O2 -Wl,--version-script=./src/bnxt_re.map   -Wl,-soname -Wl,libbnxt_re-rdmav34.so -o src/.libs/libbnxt_re-rdmav34.so
libtool: link: (cd "src/.libs" && rm -f "libbnxt_re.so" && ln -s "libbnxt_re-rdmav34.so" "libbnxt_re.so")
libtool: link: ar cr src/.libs/libbnxt_re.a  src/main.o src/verbs.o src/memory.o src/db.o
libtool: link: ranlib src/.libs/libbnxt_re.a
libtool: link: ( cd "src/.libs" && rm -f "libbnxt_re.la" && ln -s "../libbnxt_re.la" "libbnxt_re.la" )
make[1]: Leaving directory '/tmp/libbnxt'
make[1]: Entering directory '/tmp/libbnxt'
 /usr/bin/mkdir -p '/usr/local/lib'
depbase=`echo src/db.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
/bin/bash ./libtool  --tag=CC   --mode=compile gcc -DHAVE_CONFIG_H -I.    -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF $depbase.Tpo -c -o src/db.lo src/db.c &&\
mv -f $depbase.Tpo $depbase.Plo
 /bin/bash ./libtool   --mode=install /usr/bin/install -c   src/libbnxt_re.la '/usr/local/lib'
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re-rdmav34.so /usr/local/lib/libbnxt_re-rdmav34.so
libtool: install: (cd /usr/local/lib && { ln -s -f libbnxt_re-rdmav34.so libbnxt_re.so || { rm -f libbnxt_re.so && ln -s libbnxt_re-rdmav34.so libbnxt_re.so; }; })
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re.lai /usr/local/lib/libbnxt_re.la
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re.a /usr/local/lib/libbnxt_re.a
libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF src/.deps/db.Tpo -c src/db.c  -fPIC -DPIC -o src/.libs/db.o
libtool: install: chmod 644 /usr/local/lib/libbnxt_re.a
libtool: install: ranlib /usr/local/lib/libbnxt_re.a
libtool: finish: PATH="/opt/venv/bin:/opt/rocm/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin" ldconfig -n /usr/local/lib
----------------------------------------------------------------------
Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the '-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the 'LD_RUN_PATH' environment variable
     during linking
   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to '/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
make  install-exec-hook
make[2]: Entering directory '/tmp/libbnxt'
Installed libbnxt_re version 231.0.162.0
/tmp/libbnxt
make[2]: Leaving directory '/tmp/libbnxt'
 /usr/bin/mkdir -p '/usr/local/etc/libibverbs.d'
 /usr/bin/install -c -m 644 bnxt_re.driver '/usr/local/etc/libibverbs.d'
make[1]: Leaving directory '/tmp/libbnxt'
make: Leaving directory '/tmp/libbnxt'
[NODE-0(gpu-11)] [INFO] Rebuilding libbnxt done.
[NODE-0(gpu-11)] [INFO] ========== Training tuning info ==========
[NODE-0(gpu-11)] [INFO] TE_HIPBLASLT_TUNING: 
[NODE-0(gpu-11)] [INFO] TE_HIPBLASLT_TUNING_RUN_COUNT: 10
[NODE-0(gpu-11)] [INFO] TE_HIPBLASLT_TUNING_ALGO_COUNT: 50
[NODE-0(gpu-11)] [INFO] PRIMUS_HIPBLASLT_TUNING_STAGE: 
[NODE-0(gpu-11)] [INFO] HIPBLASLT_LOG_MASK: 
[NODE-0(gpu-11)] [INFO] HIPBLASLT_LOG_FILE: 
[NODE-0(gpu-11)] [INFO] HIPBLASLT_LOG_LEVEL: 
[NODE-0(gpu-11)] [INFO] HIPBLASLT_TUNING_OVERRIDE_FILE: 

libtool: compile:  gcc -DHAVE_CONFIG_H -I. -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -MT src/db.lo -MD -MP -MF src/.deps/db.Tpo -c src/db.c -o src/db.o >/dev/null 2>&1
[NODE-0(gpu-11)] [INFO] Running backend prepare: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/examples/megatron/prepare.py
/bin/bash ./libtool  --tag=CC   --mode=link gcc -Wall -D_GNU_SOURCE -I./src/rc-compat/v39 -Wno-address-of-packed-member -g -O2 -avoid-version -module -release rdmav34 -Wl,--version-script=./src/bnxt_re.map  -o src/libbnxt_re.la -rpath /usr/local/lib src/main.lo src/verbs.lo src/memory.lo src/db.lo   -lm -libverbs 
libtool: link: gcc -shared  -fPIC -DPIC  src/.libs/main.o src/.libs/verbs.o src/.libs/memory.o src/.libs/db.o   -lm -libverbs  -g -O2 -Wl,--version-script=./src/bnxt_re.map   -Wl,-soname -Wl,libbnxt_re-rdmav34.so -o src/.libs/libbnxt_re-rdmav34.so
libtool: link: (cd "src/.libs" && rm -f "libbnxt_re.so" && ln -s "libbnxt_re-rdmav34.so" "libbnxt_re.so")
libtool: link: ar cr src/.libs/libbnxt_re.a  src/main.o src/verbs.o src/memory.o src/db.o
libtool: link: ranlib src/.libs/libbnxt_re.a
libtool: link: ( cd "src/.libs" && rm -f "libbnxt_re.la" && ln -s "../libbnxt_re.la" "libbnxt_re.la" )
make[1]: Leaving directory '/tmp/libbnxt'
make[1]: Entering directory '/tmp/libbnxt'
 /usr/bin/mkdir -p '/usr/local/lib'
 /bin/bash ./libtool   --mode=install /usr/bin/install -c   src/libbnxt_re.la '/usr/local/lib'
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re-rdmav34.so /usr/local/lib/libbnxt_re-rdmav34.so
libtool: install: (cd /usr/local/lib && { ln -s -f libbnxt_re-rdmav34.so libbnxt_re.so || { rm -f libbnxt_re.so && ln -s libbnxt_re-rdmav34.so libbnxt_re.so; }; })
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re.lai /usr/local/lib/libbnxt_re.la
libtool: install: /usr/bin/install -c src/.libs/libbnxt_re.a /usr/local/lib/libbnxt_re.a
libtool: install: chmod 644 /usr/local/lib/libbnxt_re.a
libtool: install: ranlib /usr/local/lib/libbnxt_re.a
libtool: finish: PATH="/opt/venv/bin:/opt/rocm/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/sbin" ldconfig -n /usr/local/lib
----------------------------------------------------------------------
Libraries have been installed in:
   /usr/local/lib

If you ever happen to want to link against installed libraries
in a given directory, LIBDIR, you must either use libtool, and
specify the full pathname of the library, or use the '-LLIBDIR'
flag during linking and do at least one of the following:
   - add LIBDIR to the 'LD_LIBRARY_PATH' environment variable
     during execution
   - add LIBDIR to the 'LD_RUN_PATH' environment variable
     during linking
   - use the '-Wl,-rpath -Wl,LIBDIR' linker flag
   - have your system administrator add LIBDIR to '/etc/ld.so.conf'

See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.
----------------------------------------------------------------------
make  install-exec-hook
make[2]: Entering directory '/tmp/libbnxt'
Installed libbnxt_re version 231.0.162.0
/tmp/libbnxt
make[2]: Leaving directory '/tmp/libbnxt'
 /usr/bin/mkdir -p '/usr/local/etc/libibverbs.d'
 /usr/bin/install -c -m 644 bnxt_re.driver '/usr/local/etc/libibverbs.d'
make[1]: Leaving directory '/tmp/libbnxt'
make: Leaving directory '/tmp/libbnxt'
[NODE-1(gpu-12)] [INFO] Rebuilding libbnxt done.
[NODE-0(gpu-11)] [INFO] ========== Prepare Megatron dataset ==========
[NODE-0(gpu-11)] [INFO] BACKEND_PATH None
[NODE-0(gpu-11)] [INFO] PRIMUS_PATH is set to: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus
[NODE-0(gpu-11)] [INFO] DATA_PATH is set to: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/data
[NODE-0(gpu-11)] [INFO] EXP is set to: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/examples/megatron/configs/llama2_70B-pretrain.yaml
[NODE-0(gpu-11)] [INFO] PATCH-ARGS is set to: /tmp/primus_patch_args.WOotDN.yaml
[NODE-0(gpu-11)] [INFO] 'mock_data: true', Skipping dataset preparation.
[NODE-0(gpu-11)] [INFO] No backend_path provided, falling back to: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[NODE-0(gpu-11)] [INFO] Building Megatron dataset helper in /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/datasets
g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/opt/venv/lib/python3.10/site-packages/pybind11/include helpers.cpp -o helpers_cpp.cpython-310-x86_64-linux-gnu.so
g++ -O3 -Wall -shared -std=c++11 -fPIC -fdiagnostics-color -I/usr/include/python3.10 -I/opt/venv/lib/python3.10/site-packages/pybind11/include helpers.cpp -o helpers_cpp.cpython-310-x86_64-linux-gnu.so
In file included from [01m[Khelpers.cpp:12[m[K:
[01m[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:[m[K In function [01m[Kvoid build_exhaustive_blending_indices(pybind11::array_t<short int>&, pybind11::array_t<long int>&, const pybind11::array_t<long int>&, int32_t)[m[K:
[01m[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:494:14:[m[K [01;35m[Kwarning: [m[K[01m[Kerror_argmax[m[K may be used uninitialized in this function [[01;35m[K-Wmaybe-uninitialized[m[K]
  494 |     return [01;35m[Ki * strides[[m[KDim] + byte_offset_unsafe<Dim + 1>(strides, index...);
      |            [01;35m[K~~^~~~~~~~~~[m[K
[01m[Khelpers.cpp:49:13:[m[K [01;36m[Knote: [m[K[01m[Kerror_argmax[m[K was declared here
   49 |     int64_t [01;36m[Kerror_argmax[m[K;
      |             [01;36m[K^~~~~~~~~~~~[m[K
In file included from [01m[Khelpers.cpp:12[m[K:
[01m[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:[m[K In function [01m[Kvoid build_exhaustive_blending_indices(pybind11::array_t<short int>&, pybind11::array_t<long int>&, const pybind11::array_t<long int>&, int32_t)[m[K:
[01m[K/opt/venv/lib/python3.10/site-packages/pybind11/include/pybind11/numpy.h:494:14:[m[K [01;35m[Kwarning: [m[K[01m[Kerror_argmax[m[K may be used uninitialized in this function [[01;35m[K-Wmaybe-uninitialized[m[K]
  494 |     return [01;35m[Ki * strides[[m[KDim] + byte_offset_unsafe<Dim + 1>(strides, index...);
      |            [01;35m[K~~^~~~~~~~~~[m[K
[01m[Khelpers.cpp:49:13:[m[K [01;36m[Knote: [m[K[01m[Kerror_argmax[m[K was declared here
   49 |     int64_t [01;36m[Kerror_argmax[m[K;
      |             [01;36m[K^~~~~~~~~~~~[m[K
Created path: './output/amd/root/llama2_70B-pretrain'
[NODE-0(gpu-11)] [INFO] Loading patch args from /tmp/primus_patch_args.WOotDN.yaml
[NODE-0(gpu-11)] [INFO] Patched TRAIN args:  --backend_path /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[NODE-0(gpu-11)] [INFO] Launching distributed training with command: torchrun --nproc_per_node 8 --nnodes 2 --node_rank 0 --master_addr gpu-11 --master_port 12345  primus/cli/main.py train pretrain --config examples/megatron/configs/llama2_70B-pretrain.yaml  --backend_path /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM --micro_batch_size 10 --global_batch_size 640 --recompute_num_layers 80 --no_fp8_weight_transpose_cache true --fp8 hybrid
[NODE-1(gpu-12)] [INFO] Launching distributed training with command: torchrun --nproc_per_node 8 --nnodes 2 --node_rank 1 --master_addr gpu-11 --master_port 12345  primus/cli/main.py train pretrain --config examples/megatron/configs/llama2_70B-pretrain.yaml  --backend_path /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM --micro_batch_size 10 --global_batch_size 640 --recompute_num_layers 80 --no_fp8_weight_transpose_cache true --fp8 hybrid
W1114 13:53:43.100000 26772 torch/distributed/run.py:803] 
W1114 13:53:43.100000 26772 torch/distributed/run.py:803] *****************************************
W1114 13:53:43.100000 26772 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:53:43.100000 26772 torch/distributed/run.py:803] *****************************************
W1114 13:53:43.190000 26778 torch/distributed/run.py:803] 
W1114 13:53:43.190000 26778 torch/distributed/run.py:803] *****************************************
W1114 13:53:43.190000 26778 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W1114 13:53:43.190000 26778 torch/distributed/run.py:803] *****************************************
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[Primus] sys.path.insert: /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[WARNING  | transformer_engine.pytorch.dot_product_attention.utils]: Supported flash-attn versions are >= 2.1.1, <= 2.8.0.post2. Found flash-attn 2.8.3.
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] start build [module_aiter_enum] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_aiter_enum
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_aiter_enum
[aiter] start build [module_aiter_enum] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_aiter_enum
[92mSuccessfully preprocessed all matching files.[0m
[92mSuccessfully preprocessed all matching files.[0m
[aiter] finish build [module_aiter_enum], cost 13.23476680s
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
[aiter] finish build [module_aiter_enum], cost 13.50741507s
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/apex/transformer/functional/fused_rope.py:49: UserWarning: Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0
  warnings.warn("Aiter backend is selected for fused RoPE. This has lower precision. To disable aiter, export USE_ROCM_AITER_ROPE_BACKEND=0", UserWarning)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
/opt/venv/lib/python3.10/site-packages/torchao/utils.py:408: UserWarning: TORCH_VERSION_AT_LEAST_2_5 is deprecated and will be removed in torchao 0.14.0
  warnings.warn(self.msg)
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:425]: MegatronTrainer: monkey patch TopKRouter...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:502]: MegatronTrainer: Patching torch_FSDP2 with Primus implementation...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:520]: MegatronTrainer: torch_FSDP2 patch applied successfully.[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:295]: MegatronTrainer: monkey patch get_extra_te_kwargs...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:528]: MegatronTrainer: Patching FileSystemWriterAsync...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:540]: MegatronTrainer: Patch FileSystemWriterAsync successfully.[0m
[[32m20251114 13:54:06[0m][[36mrank-15/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----global_vars.py:215] : WARNING: one_logger package is required to enable e2e metrics tracking. please go to https://confluence.nvidia.com/display/MLWFO/Package+Repositories for details to install it[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[trainer.py:219]: MegatronTrainer: Patch get_fp8_context...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:617] : -run update_primus_config...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:725] : -rank:              0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:726] : -local_rank:        0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:727] : -world_size:        16[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:744] : -save:              /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/output/amd/root/llama2_70B-pretrain/checkpoints[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:751] : -auto_continue_train:False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:787] : -disable_tensorboard:True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:788] :   -tensorboard_dir: None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[---------trainer.py:804] : args.wandb_project is disabled, as args.disable_wandb=True.[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:805] : -disable_wandb:     True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:811] :   -wandb_project:   None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:812] :   -wandb_exp_name:  None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:813] :   -wandb_save_dir:  None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:814] :   -wandb_entity:    None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:625] : -run initialize_megatron...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1028] : -load:              None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1029] : -use_checkpoint_args:False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:364] : using world size: 16, data-parallel size: 16, context-parallel size: 1, hierarchical context-parallel sizes: Nonetensor-model-parallel size: 1, encoder-tensor-model-parallel size: 0, pipeline-model-parallel size: 1, encoder-pipeline-model-parallel size: 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:529] : Number of virtual stages per pipeline stage: None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:632] : accumulate and all-reduce gradients in fp32 for bfloat16 data type.[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-------arguments.py:636] : using torch.bfloat16 for parameters ...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1021] : ------------------------ arguments ------------------------[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   account_for_embedding_in_pipeline_split ......... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   account_for_loss_in_pipeline_split .............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   accumulate_allreduce_grads_in_fp32 .............. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_beta1 ...................................... 0.9[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_beta2 ...................................... 0.95[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adam_eps ........................................ 1e-08[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_bias_linear ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_position_embedding .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   add_qkv_bias .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adlr_autoresume ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   adlr_autoresume_interval ........................ 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   align_grad_reduce ............................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   align_param_gather .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   allow_padding_num_layers ........................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   app_tag_run_name ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   app_tag_run_version ............................. 0.0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_layernorm_1p .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_query_key_layer_scaling ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_residual_connection_post_layernorm ........ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   apply_rope_fusion ............................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   async_save ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   async_tensor_model_parallel_allreduce ........... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_backend ............................... auto[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_dropout ............................... 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   attention_softmax_in_fp32 ....................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   auto_continue_train ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   auto_detect_ckpt_format ......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   auto_offload_time ............................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   barrier_with_L1_time ............................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_binary_head ................................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_embedder_type .............................. megatron[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bert_load ....................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bf16 ............................................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_dropout_fusion ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_gelu_fusion ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   bias_swiglu_fusion .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   biencoder_projection_dim ........................ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   biencoder_shared_query_context_model ............ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   block_data_path ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   calc_ft_timeouts ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   calculate_per_token_loss ........................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_large_grads ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_nan_in_loss_and_grad .................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_for_spiky_loss ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   check_weight_hash_across_dp_replicas_interval ... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_assume_constant_structure .................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_format ............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_save ............................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_convert_update_legacy_dist_opt_format ...... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_format ..................................... torch_dist[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_load ........................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_save ........................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_fully_parallel_save_deprecated ............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ckpt_step ....................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   classes_fraction ................................ 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   clip_grad ....................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   clone_scatter_output_in_embedding ............... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   config_logger_dir ............................... [0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   consumed_train_samples .......................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   consumed_valid_samples .......................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   context_parallel_size ........................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cp_comm_type .................................... p2p[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cpu_offload ..................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   create_attention_mask_in_dataloader ............. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cross_entropy_fusion_impl ....................... te[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cross_entropy_loss_fusion ....................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cuda_graph_scope ................................ full[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   cuda_graph_warmup_steps ......................... 3[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_args_path .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_cache_path ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_random_init ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_sharding_strategy ................. no_shard[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_parallel_size .............................. 16[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_path ....................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_per_class_fraction ......................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   data_sharding ................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dataloader_type ................................. cyclic[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_average_in_collective ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_bucket_size ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_num_buckets ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ddp_pad_buckets_for_high_nccl_busbw ............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   debug_scheduler_table ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_first_pipeline_num_layers ............... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_last_pipeline_num_layers ................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_num_layers .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_pipeline_manual_split_list .............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoder_seq_length .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoupled_lr .................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decoupled_min_lr ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   decrease_batch_size_if_needed ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   defer_embedding_wgrad_compute ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   deprecated_use_mcore_models ..................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   deterministic_mode .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_bottleneck_size ............................ 256[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_freeze_last_layer .......................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_head_hidden_size ........................... 2048[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_local_crops_number ......................... 10[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_local_img_size ............................. 96[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_norm_last_layer ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_teacher_temp ............................... 0.07[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_warmup_teacher_temp ........................ 0.04[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dino_warmup_teacher_temp_epochs ................. 30[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_compile_dependencies .................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_last_saving ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_primus_topk_router ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_profiler_activity_cpu ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_straggler_on_startup .................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_tensorboard ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   disable_wandb ................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dist_ckpt_format_deprecated ..................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dist_ckpt_strictness ............................ assume_ok_unexpected[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distribute_saved_activations .................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distributed_backend ............................. nccl[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   distributed_timeout_minutes ..................... 60[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   dump_pp_data .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   embedding_path .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   empty_unused_memory_level ....................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_1f1b_v ................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_cuda_graph ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_exactly_numeric_match .................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_ft_package ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_gloo_process_groups ...................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_one_logger ............................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_optimizer_post_validation ................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_primus_turbo ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_turbo_attention_float8 ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_zb_runtime ............................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   enable_zero_bubble .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_num_layers .............................. 80[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_pipeline_model_parallel_size ............ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_seq_length .............................. 4096[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   encoder_tensor_model_parallel_size .............. 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   end_weight_decay ................................ 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eod_mask_loss ................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   error_injection_rate ............................ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   error_injection_type ............................ transient_error[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eval_interval ................................... 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   eval_iters ...................................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   evidence_data_path .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_duration_in_mins ........................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_interval ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_on_missing_checkpoint ...................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exit_signal_handler ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exp_avg_dtype ................................... torch.float32[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   exp_avg_sq_dtype ................................ torch.float32[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   expert_model_parallel_size ...................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   expert_tensor_parallel_size ..................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   external_cuda_graph ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ffn_hidden_size ................................. 28672[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   file_sink_level ................................. DEBUG[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   finetune ........................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   first_last_layers_bf16 .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   flash_decode .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp16 ............................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp16_lm_cross_entropy ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp32_residual_connection ........................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8 ............................................. hybrid[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_amax_compute_algo ........................... max[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_amax_history_len ............................ 1024[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_interval .................................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_margin ...................................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_param_gather ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_recipe ...................................... delayed[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fp8_wgrad ....................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   framework ....................................... megatron[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   fused_padded_mla_attention ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   global_batch_size ............................... 640[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   grad_reduce_in_bf16 ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   gradient_accumulation_fusion .................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   gradient_reduce_div_fusion ...................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   group_query_attention ........................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   head_lr_mult .................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   heterogeneous_layers_config_encoded_json ........ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   heterogeneous_layers_config_path ................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hidden_dropout .................................. 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hidden_size ..................................... 8192[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hierarchical_context_parallel_sizes ............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_attention_ratio .......................... 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_mlp_ratio ................................ 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hybrid_override_pattern ......................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   hysteresis ...................................... 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ict_head_size ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   ict_load ........................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   img_h ........................................... 224[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   img_w ........................................... 224[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   indexer_batch_size .............................. 128[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   indexer_log_interval ............................ 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_batch_times_seqlen_threshold .......... -1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_guaranteed_fraction  0.2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_overflow_factor  None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_buffer_size_gb ....... 40.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_max_requests_override  None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_dynamic_batching_max_tokens_override .. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_max_requests .......................... 8[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_max_seq_length ........................ 2560[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inference_rng_tracker ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_method_std ................................. 0.008[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_method_xavier_uniform ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   init_model_with_meta_device ..................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   initial_loss_scale .............................. 4294967296[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   inprocess_restart ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   interleave_group_size ........................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   is_hybrid_model ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   iter_per_epoch .................................. 1250[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   iterations_to_skip .............................. [][0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   keep_fp8_transpose_cache_when_using_custom_fsdp . False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   kv_channels ..................................... 128[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   kv_lora_rank .................................... 32[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lazy_mpu_init ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   load ............................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   local_rank ...................................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_avg_reset_interval .......................... 50[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_avg_skip_iterations ......................... 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_batch_size_to_tensorboard ................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_interval .................................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_learning_rate_to_tensorboard ................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_loss_scale_to_tensorboard ................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_memory_to_tensorboard ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_num_zeros_in_grad ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_params_norm ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_progress .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_straggler ................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_throughput .................................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_timers_to_tensorboard ....................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_validation_ppl_to_tensorboard ............... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   log_world_size_to_tensorboard ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   logging_level ................................... 10[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   loss_scale ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   loss_scale_window ............................... 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr .............................................. 1e-05[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_iters .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_samples ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_decay_style .................................. cosine[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_fraction .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_init .................................. 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_iters ................................. 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_warmup_samples ............................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_iters .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_samples ............................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   lr_wsd_decay_style .............................. exponential[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   main_grads_dtype ................................ torch.float32[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   main_params_dtype ............................... torch.float32[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   make_vocab_size_divisible_by .................... 128[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc ....................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc_eval .................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   manual_gc_interval .............................. 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_factor ..................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_prob ....................................... 0.15[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mask_type ....................................... random[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   masked_softmax_fusion ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   max_position_embeddings ......................... 4096[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   max_tokens_to_oom ............................... 12000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   memory_snapshot_path ............................ snapshot.pickle[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   merge_file ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   micro_batch_size ................................ 10[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   microbatch_group_size_per_vp_stage .............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   min_loss_scale .................................. 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   min_lr .......................................... 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mmap_bin_files .................................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mock_data ....................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_aux_loss_coeff .............................. 0.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_enable_deepep ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_expert_capacity_factor ...................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_extended_tp ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_ffn_hidden_size ............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_grouped_gemm ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_input_jitter_eps ............................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_layer_freq .................................. 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_layer_recompute ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_pad_expert_input_to_capacity ................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_per_layer_logging ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_permute_fusion .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_bias_update_rate ..................... 0.001[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_dtype ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_enable_expert_bias ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_force_load_balancing ................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_group_topk ........................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_load_balancing_type .................. aux_loss[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_num_groups ........................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_pre_softmax .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_score_function ....................... softmax[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_topk ................................. 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_router_topk_scaling_factor .................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_shared_expert_intermediate_size ............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_shared_expert_overlap ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_token_dispatcher_type ....................... allgather[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_token_drop_policy ........................... probs[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_fused_router_with_aux_score ............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_legacy_grouped_gemm ..................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_use_upcycling ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   moe_z_loss_coeff ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mscale .......................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mscale_all_dim .................................. 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mtp_loss_scaling_factor ......................... 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   mtp_num_layers .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   multi_latent_attention .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   name ............................................ pre_trainer[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   nccl_communicator_config_path ................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_fp8_weight_transpose_cache ................... true[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_load_optim ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_load_rng ..................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_persist_layer_norm ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_save_optim ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   no_save_rng ..................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_ckpt_type ........................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_global_ckpt_dir .................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_local_ckpt_algo .................. fully_parallel[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_local_ckpt_dir ................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   non_persistent_save_interval .................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   norm_epsilon .................................... 1e-06[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   normalization ................................... RMSNorm[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_attention_heads ............................. 64[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_channels .................................... 3[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_classes ..................................... 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_dataset_builder_threads ..................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_distributed_optimizer_instances ............. 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_experts ..................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers ...................................... 80[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers_at_end_in_bf16 ....................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers_at_start_in_bf16 ..................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_layers_per_virtual_pipeline_stage ........... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_query_groups ................................ 8[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_seq_splits .................................. 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_virtual_stages_per_pipeline_rank ............ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   num_workers ..................................... 8[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   offload_chunk_num ............................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   offload_overlap_sr .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   offload_time .................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_async ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_project .............................. megatron-lm[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   one_logger_run_name ............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   onnx_safe ....................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   openai_gelu ..................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer ....................................... adam[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer_cpu_offload ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   optimizer_offload_fraction ...................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   output_bert_embeddings .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_cpu_optimizer_d2h_h2d ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_grad_reduce ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_p2p_comm ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_param_gather ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   overlap_param_gather_with_optimizer_step ........ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   override_opt_param_scheduler .................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   parallel_output ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   params_dtype .................................... torch.bfloat16[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   patch_dim ....................................... 16[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   patch_zero_bubble ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   per_split_data_args_path ........................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   perform_initialization .......................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pin_cpu_grads ................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pin_cpu_params .................................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_comm_backend ............ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_size .................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pipeline_model_parallel_split_rank .............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   position_embedding_type ......................... rope[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pp_warmup ....................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pre_communication_optimization .................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   pretrained_checkpoint ........................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile ......................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_memory_iter ............................. -1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_ranks ................................... [0][0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_step_end ................................ 12[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   profile_step_start .............................. 10[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   q_lora_rank ..................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_head_dim ..................................... 128[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_layernorm .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   qk_pos_emb_head_dim ............................. 64[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   query_in_block_prob ............................. 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rampup_batch_size ............................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rank ............................................ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_granularity ........................... full[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_method ................................ block[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   recompute_num_layers ............................ 80[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   record_memory_history ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication ..................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication_factor .............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   replication_jump ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rerun_mode ...................................... disabled[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   reset_attention_mask ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   reset_position_ids .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   result_rejected_tracker_filename ................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_report_topk_accuracies ................ [][0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_score_scaling ......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retriever_seq_length ............................ 256[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_add_retriever ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_attention_gate ............................ 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_cyclic_train_iters ........................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_attention_dropout ................. 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_hidden_dropout .................... 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_encoder_layers ............................ 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_num_neighbors ............................. 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_num_retrieved_chunks ...................... 2[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_project_dir ............................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   retro_verify_neighbor_count ..................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rope_scaling_factor ............................. 8.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_base ..................................... 10000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_interleaved .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_percent .................................. 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_scaling_factor ........................... 40[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   rotary_seq_len_interpolation_factor ............. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   run_workload_inspector_server ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   s3_cache_path ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sample_rate ..................................... 1.0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   save ............................................ /shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/output/amd/root/llama2_70B-pretrain/checkpoints[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   save_interval ................................... 20000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   scatter_gather_tensors_in_pipeline .............. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   seed ............................................ 1234[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   seq_length ...................................... 4096[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sequence_parallel ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sgd_momentum .................................... 0.9[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   short_seq_prob .................................. 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   sink_level ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   skip_train ...................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   skipped_train_samples ........................... 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   spec ............................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   split ........................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   squared_relu .................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   standalone_embedding_stage ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   start_weight_decay .............................. 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   stderr_sink_level ............................... DEBUG[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   straggler_ctrlr_port ............................ 65535[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   straggler_minmax_count .......................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   suggested_communication_unit_size ............... 400000000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   swiglu .......................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   swin_backbone_type .............................. tiny[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   te_rng_tracker .................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensor_model_parallel_size ...................... 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_dir ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_log_interval ........................ 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tensorboard_queue_size .......................... 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   test_data_path .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   test_mode ....................................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_num_special_tokens ..................... 1000[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_pattern ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tiktoken_special_tokens ......................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   timing_log_level ................................ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   timing_log_option ............................... minmax[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   titles_data_path ................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tokenizer_model ................................. NousResearch/Llama-2-70b-hf[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tokenizer_type .................................. Llama2Tokenizer[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bootstrap_backend ....................... nccl[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bulk_dgrad .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_bulk_wgrad .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_ag .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_cfg ............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_rs .............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_overlap_rs_dgrad ........................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_split_ag ................................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   tp_comm_split_rs ................................ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_data_path ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_iters ..................................... 50[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_samples ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   train_sync_interval ............................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   trainable ....................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   transformer_impl ................................ transformer_engine[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   transformer_pipeline_model_parallel_size ........ 1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   untie_embeddings_and_output_weights ............. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_checkpoint_args ............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_checkpoint_opt_param_scheduler .............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_cpu_initialization .......................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_custom_fsdp ................................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_deprecated_20241209_moe_layer ............... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_dist_ckpt ................................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_dist_ckpt_deprecated ........................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_distributed_optimizer ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_flash_attn .................................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_legacy_models ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_mp_args_from_checkpoint_args ................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_one_sent_docs ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_persistent_ckpt_worker ...................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_precision_aware_optimizer ................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_pytorch_profiler ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_ring_exchange_p2p ........................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rocm_mem_info ............................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rocm_mem_info_iters ......................... [1, 2][0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rope_scaling ................................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_rotary_position_embeddings .................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_tokenizer_model_from_checkpoint_args ........ True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_torch_fsdp2 ................................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_torch_optimizer_for_cpu_offload ............. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_tp_pp_dp_mapping ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_attention ............................. True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_grouped_mlp ........................... True[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   use_turbo_parallel_linear ....................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   v_head_dim ...................................... 128[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   valid_data_path ................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   variable_seq_lengths ............................ False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   virtual_pipeline_model_parallel_size ............ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_backbone_type ............................ vit[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_pretraining .............................. False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vision_pretraining_type ......................... classify[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_extra_ids ................................. 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_file ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   vocab_size ...................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_entity .................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_exp_name .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_project ................................... None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wandb_save_dir .................................. None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   weight_decay .................................... 0.1[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   weight_decay_incr_style ......................... constant[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   wgrad_deferral_limit ............................ 0[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   world_size ...................................... 16[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   yaml_cfg ........................................ None[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_adaptive_memory_limit_percentile .... 85[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_max_pending_backward ................ auto[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_pipeline_timers_end_iter ............ 110[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_pipeline_timers_start_iter .......... 100[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_v_schedule .......................... False[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1028] :   zero_bubble_v_schedule_mem_setup ................ half[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------arguments.py:1029] : -------------------- end of arguments ---------------------[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1055] : -monkey patch megatron.training.global_vars._set_wandb_writer...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1060] : -set_global_variables...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1065] : -build_tokenizer...[0m
[[32m20251114 13:54:06[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------tokenizer.py:40] : -building Llama2Tokenizer tokenizer...[0m
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[--------tokenizer.py:63] :  > padded vocab (size: 32000) with 0 dummy tokens (new size: 32000)[0m
RerunStateMachine initialized in mode disabled
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1118] : -lazy_mpu_init:     None[0m
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1095] : -initialize_distributed...[0m
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:315] : > initializing torch distributed ...[0m
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15[Gloo] Rank 
[Gloo] Rank 3 is connected to 15[Gloo] Rank  peer ranks. Expected number of connected peer ranks is : 4 is connected to 1515 peer ranks. Expected number of connected peer ranks is : 151
 is connected to 
15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank [Gloo] Rank 7 is connected to 615 is connected to  peer ranks. Expected number of connected peer ranks is : 1515[Gloo] Rank [Gloo] Rank 
5 peer ranks. Expected number of connected peer ranks is : 2 is connected to  is connected to 151515 peer ranks.  peer ranks. Expected number of connected peer ranks is : 
Expected number of connected peer ranks is : 1515

[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 14[Gloo] Rank  is connected to 1513 peer ranks.  is connected to 15Expected number of connected peer ranks is :  peer ranks. Expected number of connected peer ranks is : 1515

[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 1 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 0 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:366] : > initialized tensor model parallel with size 1[0m
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[------initialize.py:370] : > initialized pipeline model parallel with size 1[0m
[[32m20251114 13:54:07[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1099] : -seeds:             1234[0m
[Gloo] Rank 2 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 4 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 3 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 5 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 6 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 7 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 8 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 9 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 10 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 11 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 12 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 13 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 15 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
[Gloo] Rank 14 is connected to 15 peer ranks. Expected number of connected peer ranks is : 15
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:676] : time to initialize megatron (seconds): 9.332[0m
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after megatron is initialized] datetime: 2025-11-14 13:54:15 [0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:878] : -setup_model_and_optimizer...[0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1167] : use pt backend...[0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1175] : -run get_model[0m
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : building GPT model ...[0m
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
/shared/amdgpu/home/hisaki_ohara_7kq/Projects/Primus/third_party/Megatron-LM/megatron/core/models/gpt/gpt_layer_specs.py:94: UserWarning: The fp8 argument in "get_gpt_layer_with_transformer_engine_spec" has been deprecated and will be removed soon. Please update your code accordingly.
  warnings.warn(
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-------training.py:1050] :  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 68976648192[0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[torch_fully_sharded_data_parallel.py:49]: PrimusTorchFullyShardedDataParallel: not use args: {'disable_bucketing': False}[0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1177] : [PrimusTorchFullyShardedDataParallel(
  (module): FSDPFloat16Module(
    (module): GPTModel(
      (embedding): FSDPLanguageModelEmbedding(
        (word_embeddings): VocabParallelEmbedding()
        (embedding_dropout): Dropout(p=0.0, inplace=False)
      )
      (rotary_pos_emb): FSDPRotaryEmbedding()
      (decoder): TransformerBlock(
        (layers): ModuleList(
          (0-79): 80 x FSDPTransformerLayer(
            (input_layernorm): IdentityOp()
            (self_attention): SelfAttention(
              (core_attention): PrimusTurboAttention(
                (flash_attention): FlashAttention()
                (fused_attention): FusedAttention()
                (unfused_attention): UnfusedDotProductAttention(
                  (scale_mask_softmax): FusedScaleMaskSoftmax()
                  (attention_dropout): Dropout(p=0.0, inplace=False)
                )
              )
              (linear_proj): TERowParallelLinear(in_features=8192, out_features=8192, bias=False, TP=1)
              (linear_qkv): TELayerNormColumnParallelLinear(in_features=8192, out_features=10240, bias=False, TP=1)
              (q_layernorm): IdentityOp()
              (k_layernorm): IdentityOp()
            )
            (pre_cross_attn_layernorm): IdentityOp()
            (cross_attention): IdentityOp()
            (cross_attn_bda): IdentityFuncOp()
            (pre_mlp_layernorm): IdentityOp()
            (mlp): MLP(
              (linear_fc1): TELayerNormColumnParallelLinear(in_features=8192, out_features=57344, bias=False, TP=1)
              (linear_fc2): TERowParallelLinear(in_features=28672, out_features=8192, bias=False, TP=1)
            )
          )
        )
        (final_layernorm): RMSNorm()
      )
      (output_layer): FSDPColumnParallelLinear(in_features=8192, out_features=32000, bias=False, TP=1)
    )
  )
)][0m
[[32m20251114 13:54:15[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1191] : -run get_megatron_optimizer[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after model, optimizer, and learning rate scheduler are built] datetime: 2025-11-14 13:54:16 [0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : > building train, validation, and test datasets ...[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :  > datasets target sizes (minimum size):[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     train:      32000[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     validation: 0[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] :     test:       0[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:984] : > building train, validation, and test datasets for GPT ...[0m
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
Unable to save MockGPTDataset indexes because path_to_cache is None
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:989] : > finished creating GPT datasets ...[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after dataloaders are built] datetime: 2025-11-14 13:54:16 [0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[---------trainer.py:931] : done with setup ...[0m
[[32m20251114 13:54:16[0m][[36mrank-15/16[0m][[34m[1mDEBUG[0m] [34m[1m[----------timers.py:417] : (min, max) time across ranks (ms):
    model-and-optimizer-setup ......................: (406.40, 858.03)
    train/valid/test-data-iterators-setup ..........: (25.72, 33.08)[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1321] : training ...[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[1mINFO [0m] [1m[--------trainer.py:1461] : Setting rerun_state_machine.current_iteration to 0...[0m
[[32m20251114 13:54:16[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [before the start of training step] datetime: 2025-11-14 13:54:16 [0m
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
[[32m20251114 13:54:19[0m][[36mrank-0/16[0m][[33m[1mWARNING[0m] [33m[1m[fp8_utils.py:148]: WARNING: Primus-Turbo FP8 delayed not work since Primus-Turbo not support delayed scaling..[0m
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] start build [module_rope_general_fwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] start build [module_rope_general_fwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_fwd
[[32m20251114 13:54:32[0m][[36mrank-9/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[[32m20251114 13:54:32[0m][[36mrank-7/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[aiter] finish build [module_rope_general_fwd], cost 95.60848052s
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] start build [module_fmha_v3_fwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_fmha_v3_fwd
[aiter] finish build [module_rope_general_fwd], cost 95.67535055s
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] start build [module_fmha_v3_fwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_fwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_fwd
[[32m20251114 13:56:01[0m][[36mrank-9/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[[32m20251114 13:56:01[0m][[36mrank-7/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[aiter] finish build [module_fmha_v3_fwd], cost 23.41487186s
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] finish build [module_fmha_v3_fwd], cost 24.16821835s
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_fwd(q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, return_softmax_lse: bool, return_dropout_randval: bool, out: Optional[torch.Tensor] = None, bias: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_fmha_v3_bwd
[aiter] start build [module_fmha_v3_bwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_fmha_v3_bwd
[aiter] start build [module_fmha_v3_bwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_fmha_v3_bwd
[[32m20251114 13:58:16[0m][[36mrank-6/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[[32m20251114 13:58:16[0m][[36mrank-14/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[aiter] finish build [module_fmha_v3_bwd], cost 35.81803231s
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] start build [module_rope_general_bwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[[32m20251114 13:58:40[0m][[36mrank-6/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[aiter] finish build [module_fmha_v3_bwd], cost 36.16093640s
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] start build [module_rope_general_bwd] under /opt/venv/lib/python3.10/site-packages/aiter/jit/build/module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[[32m20251114 13:58:40[0m][[36mrank-14/16[0m][[34m[1mDEBUG[0m] [34m[1m[--hipify_python.py:1346] : [92mSuccessfully preprocessed all matching files.[0m[0m
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] type hints mismatch, override to --> fmha_v3_bwd(dout: torch.Tensor, q: torch.Tensor, k: torch.Tensor, v: torch.Tensor, out: torch.Tensor, softmax_lse: torch.Tensor, dropout_p: float, softmax_scale: float, is_causal: bool, window_size_left: int, window_size_right: int, deterministic: bool, is_v3_atomic_fp32: bool, how_v3_bf16_cvt: int, dq: Optional[torch.Tensor] = None, dk: Optional[torch.Tensor] = None, dv: Optional[torch.Tensor] = None, alibi_slopes: Optional[torch.Tensor] = None, rng_state: Optional[torch.Tensor] = None, gen: Optional[torch.Generator] = None) -> list[torch.Tensor]
[aiter] waiting for baton release at /opt/venv/lib/python3.10/site-packages/aiter/jit/build/lock_module_rope_general_bwd
[aiter] finish build [module_rope_general_bwd], cost 91.44357915s
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] finish build [module_rope_general_bwd], cost 91.33854318s
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
[aiter] type hints mismatch, override to --> rope_bwd_impl(arg0: torch.Tensor, arg1: torch.Tensor, arg2: torch.Tensor, arg3: int, arg4: bool, arg5: bool) -> None
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[[32m20251114 14:01:41[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        1/      50 | consumed samples:          640 | elapsed time per iteration (ms): 444692.3/444692.3 | hip mem usage/free/total/usage_ratio: 193.14GB/62.85GB/255.98GB/75.45% | rocm mem usage/free/total/usage_ratio: 196.66GB/59.32GB/255.98GB/76.83% | throughput per GPU (TFLOP/s/GPU): 163.8/163.8 | tokens per GPU (tokens/s/GPU): 368.4/368.4 | learning rate: 5.000000E-06 | global batch size:   640 | lm loss: 1.064494E+01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 253819888.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:136] : Number of parameters in transformer block in billions:  68.45[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:145] : Number of parameters in embedding layers in billions: 0.52[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:149] : Total number of parameters in billions: 68.98[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:162] : Number of parameters in most loaded shard in billions: 68.9780[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[theoretical_memory_usage.py:273] : Theoretical memory footprints: weight and optimizer=1184085.28 MB[0m
[[32m20251114 14:01:41[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:263] : [Rank 0] (after 1 iterations) memory (MB) | allocated: 139477.38671875 | max allocated: 169964.1650390625 | reserved: 186458.0 | max reserved: 186458.0[0m
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
/opt/venv/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:4814: UserWarning: No device id is provided via `init_process_group` or `barrier `. Using the current device set by the user. 
  warnings.warn(  # warn only once
[[32m20251114 14:03:13[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        2/      50 | consumed samples:         1280 | elapsed time per iteration (ms): 92809.9/268751.1 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | rocm mem usage/free/total/usage_ratio: 230.57GB/25.42GB/255.98GB/90.07% | throughput per GPU (TFLOP/s/GPU): 784.7/474.2 | tokens per GPU (tokens/s/GPU): 1765.3/1066.9 | learning rate: 1.000000E-05 | global batch size:   640 | lm loss: 1.064461E+01 | loss scale: 1.0 | grad norm: 0.001 | num zeros: 246558784.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:263: DeprecationWarning: torch.get_autocast_gpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cuda') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:856.)
  gpu_autocast_dtype = torch.get_autocast_gpu_dtype()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:268: DeprecationWarning: torch.is_autocast_cpu_enabled() is deprecated. Please use torch.is_autocast_enabled('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:732.)
  cpu_autocast_enabled = torch.is_autocast_cpu_enabled()
/opt/venv/lib/python3.10/site-packages/transformer_engine/pytorch/distributed.py:269: DeprecationWarning: torch.get_autocast_cpu_dtype() is deprecated. Please use torch.get_autocast_dtype('cpu') instead. (Triggered internally at /pytorch/torch/csrc/autograd/init.cpp:865.)
  cpu_autocast_dtype = torch.get_autocast_cpu_dtype()
[[32m20251114 14:04:46[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        3/      50 | consumed samples:         1920 | elapsed time per iteration (ms): 92597.4/92597.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.5/786.5 | tokens per GPU (tokens/s/GPU): 1769.4/1769.4 | learning rate: 9.989295E-06 | global batch size:   640 | lm loss: 9.504762E+00 | loss scale: 1.0 | grad norm: 0.001 | num zeros: 246898640.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:06:19[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        4/      50 | consumed samples:         2560 | elapsed time per iteration (ms): 92631.1/92614.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/786.3 | tokens per GPU (tokens/s/GPU): 1768.7/1769.1 | learning rate: 9.957224E-06 | global batch size:   640 | lm loss: 6.553284E+00 | loss scale: 1.0 | grad norm: 0.001 | num zeros: 244760288.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:07:51[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        5/      50 | consumed samples:         3200 | elapsed time per iteration (ms): 92698.8/92642.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.6/786.1 | tokens per GPU (tokens/s/GPU): 1767.4/1768.5 | learning rate: 9.903926E-06 | global batch size:   640 | lm loss: 4.453575E+00 | loss scale: 1.0 | grad norm: 0.002 | num zeros: 245999680.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:09:24[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        6/      50 | consumed samples:         3840 | elapsed time per iteration (ms): 92744.5/92667.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.2/785.9 | tokens per GPU (tokens/s/GPU): 1766.6/1768.0 | learning rate: 9.829630E-06 | global batch size:   640 | lm loss: 2.442042E+00 | loss scale: 1.0 | grad norm: 0.001 | num zeros: 245845888.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:10:57[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        7/      50 | consumed samples:         4480 | elapsed time per iteration (ms): 92782.9/92690.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 784.9/785.7 | tokens per GPU (tokens/s/GPU): 1765.8/1767.6 | learning rate: 9.734651E-06 | global batch size:   640 | lm loss: 1.520059E+00 | loss scale: 1.0 | grad norm: 0.001 | num zeros: 249393712.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:12:30[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        8/      50 | consumed samples:         5120 | elapsed time per iteration (ms): 92758.3/92702.2 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.1/785.6 | tokens per GPU (tokens/s/GPU): 1766.3/1767.4 | learning rate: 9.619398E-06 | global batch size:   640 | lm loss: 1.067309E+00 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 249514784.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:14:02[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration        9/      50 | consumed samples:         5760 | elapsed time per iteration (ms): 92766.4/92711.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.0/785.5 | tokens per GPU (tokens/s/GPU): 1766.2/1767.2 | learning rate: 9.484364E-06 | global batch size:   640 | lm loss: 8.266160E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 253590192.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:15:35[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       10/      50 | consumed samples:         6400 | elapsed time per iteration (ms): 92697.9/92709.7 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.6/785.5 | tokens per GPU (tokens/s/GPU): 1767.5/1767.2 | learning rate: 9.330127E-06 | global batch size:   640 | lm loss: 7.122028E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 256875040.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:17:08[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       11/      50 | consumed samples:         7040 | elapsed time per iteration (ms): 92654.9/92703.6 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.0/785.6 | tokens per GPU (tokens/s/GPU): 1768.3/1767.4 | learning rate: 9.157348E-06 | global batch size:   640 | lm loss: 5.721101E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 258380720.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:18:40[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       12/      50 | consumed samples:         7680 | elapsed time per iteration (ms): 92725.8/92705.8 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.4/785.6 | tokens per GPU (tokens/s/GPU): 1766.9/1767.3 | learning rate: 8.966766E-06 | global batch size:   640 | lm loss: 5.489133E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 260115936.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:20:13[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       13/      50 | consumed samples:         8320 | elapsed time per iteration (ms): 92681.4/92703.6 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.8/785.6 | tokens per GPU (tokens/s/GPU): 1767.8/1767.4 | learning rate: 8.759199E-06 | global batch size:   640 | lm loss: 4.724897E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 263377712.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:21:46[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       14/      50 | consumed samples:         8960 | elapsed time per iteration (ms): 92634.0/92697.8 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/785.6 | tokens per GPU (tokens/s/GPU): 1768.7/1767.5 | learning rate: 8.535534E-06 | global batch size:   640 | lm loss: 4.332077E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 266467264.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:23:18[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       15/      50 | consumed samples:         9600 | elapsed time per iteration (ms): 92682.9/92696.6 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.7/785.6 | tokens per GPU (tokens/s/GPU): 1767.7/1767.5 | learning rate: 8.296729E-06 | global batch size:   640 | lm loss: 4.036992E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 267208512.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:24:51[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       16/      50 | consumed samples:        10240 | elapsed time per iteration (ms): 92683.8/92695.7 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.7/785.6 | tokens per GPU (tokens/s/GPU): 1767.7/1767.5 | learning rate: 8.043807E-06 | global batch size:   640 | lm loss: 3.822933E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 269098880.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:26:24[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       17/      50 | consumed samples:        10880 | elapsed time per iteration (ms): 92643.7/92692.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.1/785.7 | tokens per GPU (tokens/s/GPU): 1768.5/1767.6 | learning rate: 7.777851E-06 | global batch size:   640 | lm loss: 3.427497E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 269287360.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:27:56[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       18/      50 | consumed samples:        11520 | elapsed time per iteration (ms): 92653.7/92689.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.0/785.7 | tokens per GPU (tokens/s/GPU): 1768.3/1767.6 | learning rate: 7.500000E-06 | global batch size:   640 | lm loss: 3.376348E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 267964432.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:29:29[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       19/      50 | consumed samples:        12160 | elapsed time per iteration (ms): 92658.4/92688.0 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.0/785.7 | tokens per GPU (tokens/s/GPU): 1768.2/1767.7 | learning rate: 7.211444E-06 | global batch size:   640 | lm loss: 3.238036E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 270553536.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:31:02[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       20/      50 | consumed samples:        12800 | elapsed time per iteration (ms): 92613.8/92683.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.3/785.7 | tokens per GPU (tokens/s/GPU): 1769.1/1767.7 | learning rate: 6.913417E-06 | global batch size:   640 | lm loss: 3.062775E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 269026048.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:32:34[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       21/      50 | consumed samples:        13440 | elapsed time per iteration (ms): 92610.0/92680.0 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/785.8 | tokens per GPU (tokens/s/GPU): 1769.1/1767.8 | learning rate: 6.607198E-06 | global batch size:   640 | lm loss: 2.992365E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 271493120.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:34:07[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       22/      50 | consumed samples:        14080 | elapsed time per iteration (ms): 92660.4/92679.0 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.9/785.8 | tokens per GPU (tokens/s/GPU): 1768.2/1767.8 | learning rate: 6.294095E-06 | global batch size:   640 | lm loss: 2.762421E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 271195424.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:35:40[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       23/      50 | consumed samples:        14720 | elapsed time per iteration (ms): 92626.5/92676.5 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/785.8 | tokens per GPU (tokens/s/GPU): 1768.8/1767.9 | learning rate: 5.975452E-06 | global batch size:   640 | lm loss: 2.787078E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 270850432.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:37:12[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       24/      50 | consumed samples:        15360 | elapsed time per iteration (ms): 92605.0/92673.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/785.8 | tokens per GPU (tokens/s/GPU): 1769.2/1767.9 | learning rate: 5.652631E-06 | global batch size:   640 | lm loss: 2.747544E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 272398368.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:38:45[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       25/      50 | consumed samples:        16000 | elapsed time per iteration (ms): 92626.5/92671.2 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/785.8 | tokens per GPU (tokens/s/GPU): 1768.8/1768.0 | learning rate: 5.327016E-06 | global batch size:   640 | lm loss: 2.573319E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 272282336.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:40:17[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       26/      50 | consumed samples:        16640 | elapsed time per iteration (ms): 92640.4/92669.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.1/785.9 | tokens per GPU (tokens/s/GPU): 1768.6/1768.0 | learning rate: 5.000000E-06 | global batch size:   640 | lm loss: 2.494211E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 272568512.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:41:50[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       27/      50 | consumed samples:        17280 | elapsed time per iteration (ms): 92633.5/92668.5 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/785.9 | tokens per GPU (tokens/s/GPU): 1768.7/1768.0 | learning rate: 4.672984E-06 | global batch size:   640 | lm loss: 2.420698E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 273947840.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:43:23[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       28/      50 | consumed samples:        17920 | elapsed time per iteration (ms): 92611.1/92666.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/785.9 | tokens per GPU (tokens/s/GPU): 1769.1/1768.1 | learning rate: 4.347369E-06 | global batch size:   640 | lm loss: 2.447017E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274792384.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:44:55[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       29/      50 | consumed samples:        18560 | elapsed time per iteration (ms): 92667.5/92666.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 785.9/785.9 | tokens per GPU (tokens/s/GPU): 1768.0/1768.1 | learning rate: 4.024549E-06 | global batch size:   640 | lm loss: 2.323377E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 272887232.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:46:28[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       30/      50 | consumed samples:        19200 | elapsed time per iteration (ms): 92623.4/92664.8 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.3/785.9 | tokens per GPU (tokens/s/GPU): 1768.9/1768.1 | learning rate: 3.705905E-06 | global batch size:   640 | lm loss: 2.346082E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 273172704.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:48:01[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       31/      50 | consumed samples:        19840 | elapsed time per iteration (ms): 92596.2/92662.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.5/785.9 | tokens per GPU (tokens/s/GPU): 1769.4/1768.1 | learning rate: 3.392803E-06 | global batch size:   640 | lm loss: 2.270166E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274187936.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:49:33[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       32/      50 | consumed samples:        20480 | elapsed time per iteration (ms): 92628.2/92661.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/785.9 | tokens per GPU (tokens/s/GPU): 1768.8/1768.2 | learning rate: 3.086583E-06 | global batch size:   640 | lm loss: 2.194581E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 273397056.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:51:06[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       33/      50 | consumed samples:        21120 | elapsed time per iteration (ms): 92608.4/92659.6 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/785.9 | tokens per GPU (tokens/s/GPU): 1769.2/1768.2 | learning rate: 2.788556E-06 | global batch size:   640 | lm loss: 2.155723E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 273794432.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:52:38[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       34/      50 | consumed samples:        21760 | elapsed time per iteration (ms): 92538.7/92655.8 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 787.0/786.0 | tokens per GPU (tokens/s/GPU): 1770.5/1768.3 | learning rate: 2.500000E-06 | global batch size:   640 | lm loss: 2.231911E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274456256.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:54:11[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       35/      50 | consumed samples:        22400 | elapsed time per iteration (ms): 92631.9/92655.1 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.2/786.0 | tokens per GPU (tokens/s/GPU): 1768.7/1768.3 | learning rate: 2.222149E-06 | global batch size:   640 | lm loss: 2.088961E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274749760.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:55:44[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       36/      50 | consumed samples:        23040 | elapsed time per iteration (ms): 92590.2/92653.2 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.5/786.0 | tokens per GPU (tokens/s/GPU): 1769.5/1768.3 | learning rate: 1.956193E-06 | global batch size:   640 | lm loss: 2.128381E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275085888.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:57:16[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       37/      50 | consumed samples:        23680 | elapsed time per iteration (ms): 92590.0/92651.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.5/786.0 | tokens per GPU (tokens/s/GPU): 1769.5/1768.4 | learning rate: 1.703271E-06 | global batch size:   640 | lm loss: 2.141566E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274190144.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 14:58:49[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       38/      50 | consumed samples:        24320 | elapsed time per iteration (ms): 92578.3/92649.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.6/786.0 | tokens per GPU (tokens/s/GPU): 1769.7/1768.4 | learning rate: 1.464466E-06 | global batch size:   640 | lm loss: 2.105250E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274901632.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:00:21[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       39/      50 | consumed samples:        24960 | elapsed time per iteration (ms): 92581.5/92647.5 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.6/786.0 | tokens per GPU (tokens/s/GPU): 1769.7/1768.4 | learning rate: 1.240801E-06 | global batch size:   640 | lm loss: 2.105690E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 273817824.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:01:54[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       40/      50 | consumed samples:        25600 | elapsed time per iteration (ms): 92557.0/92645.1 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.8/786.1 | tokens per GPU (tokens/s/GPU): 1770.2/1768.5 | learning rate: 1.033233E-06 | global batch size:   640 | lm loss: 2.110710E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 276348224.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:03:26[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       41/      50 | consumed samples:        26240 | elapsed time per iteration (ms): 92557.9/92642.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.8/786.1 | tokens per GPU (tokens/s/GPU): 1770.1/1768.5 | learning rate: 8.426520E-07 | global batch size:   640 | lm loss: 2.122814E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275289344.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:04:59[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       42/      50 | consumed samples:        26880 | elapsed time per iteration (ms): 92600.9/92641.8 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/786.1 | tokens per GPU (tokens/s/GPU): 1769.3/1768.5 | learning rate: 6.698730E-07 | global batch size:   640 | lm loss: 2.045454E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 276218528.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:06:32[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       43/      50 | consumed samples:        27520 | elapsed time per iteration (ms): 92579.9/92640.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.6/786.1 | tokens per GPU (tokens/s/GPU): 1769.7/1768.6 | learning rate: 5.156363E-07 | global batch size:   640 | lm loss: 2.081806E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275498208.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:08:04[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       44/      50 | consumed samples:        28160 | elapsed time per iteration (ms): 92556.0/92638.3 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.8/786.1 | tokens per GPU (tokens/s/GPU): 1770.2/1768.6 | learning rate: 3.806023E-07 | global batch size:   640 | lm loss: 2.045601E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274314624.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:09:37[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       45/      50 | consumed samples:        28800 | elapsed time per iteration (ms): 92611.2/92637.7 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.4/786.1 | tokens per GPU (tokens/s/GPU): 1769.1/1768.6 | learning rate: 2.653493E-07 | global batch size:   640 | lm loss: 2.049658E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274989632.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:11:09[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       46/      50 | consumed samples:        29440 | elapsed time per iteration (ms): 92580.4/92636.4 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.6/786.1 | tokens per GPU (tokens/s/GPU): 1769.7/1768.6 | learning rate: 1.703709E-07 | global batch size:   640 | lm loss: 2.079868E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 274426976.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:12:42[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       47/      50 | consumed samples:        30080 | elapsed time per iteration (ms): 92569.4/92634.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.7/786.2 | tokens per GPU (tokens/s/GPU): 1769.9/1768.7 | learning rate: 9.607360E-08 | global batch size:   640 | lm loss: 2.045771E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275921504.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:14:14[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       48/      50 | consumed samples:        30720 | elapsed time per iteration (ms): 92572.3/92633.5 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.7/786.2 | tokens per GPU (tokens/s/GPU): 1769.9/1768.7 | learning rate: 4.277569E-08 | global batch size:   640 | lm loss: 2.057424E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275123520.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:15:47[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       49/      50 | consumed samples:        31360 | elapsed time per iteration (ms): 92615.6/92633.1 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.3/786.2 | tokens per GPU (tokens/s/GPU): 1769.0/1768.7 | learning rate: 1.070538E-08 | global batch size:   640 | lm loss: 2.082218E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275576032.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:17:20[0m][[36mrank-15/16[0m][[1mINFO [0m] [1m[--------trainer.py:2382] :  iteration       50/      50 | consumed samples:        32000 | elapsed time per iteration (ms): 92574.9/92631.9 | hip mem usage/free/total/usage_ratio: 227.04GB/28.94GB/255.98GB/88.69% | throughput per GPU (TFLOP/s/GPU): 786.7/786.2 | tokens per GPU (tokens/s/GPU): 1769.8/1768.7 | learning rate: 0.000000E+00 | global batch size:   640 | lm loss: 2.013329E-01 | loss scale: 1.0 | grad norm: 0.000 | num zeros: 275332448.0 | number of skipped iterations:   0 | number of nan iterations:   0 |[0m
[[32m20251114 15:17:20[0m][[36mrank-0/16[0m][[34m[1mDEBUG[0m] [34m[1m[-----------utils.py:364] : [after training is done] datetime: 2025-11-14 15:17:20 [0m
[NODE-0(gpu-11)] [INFO] torchrun exited with code 0
[NODE-0(gpu-11)]: end, time=2025.11.14 07:53:06
[NODE-1(gpu-12)] [INFO] torchrun exited with code 0
[NODE-1(gpu-12)]: end, time=2025.11.14 07:53:07
